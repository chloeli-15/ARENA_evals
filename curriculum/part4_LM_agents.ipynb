{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [3.4] LLM Agent Evaluations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Setup (don't read just run)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "\n",
                "# os.chdir(\"c:\\\\Users\\\\styme\\\\OneDrive\\\\Documents\\\\AI STUFF\\\\Model Written Evals\\\\Code Replication\\\\ARENA_evals\\\\curriculum\")\n",
                "import wikipedia\n",
                "from wikipedia import WikipediaPage\n",
                "from wikipedia import DisambiguationError, PageError\n",
                "from openai import OpenAI\n",
                "from openai.types.chat.chat_completion_message_tool_call import (\n",
                "    ChatCompletionMessageToolCall,\n",
                ")\n",
                "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
                "from anthropic import Anthropic\n",
                "from utils import establish_client_OpenAI\n",
                "from utils import retry_with_exponential_backoff\n",
                "from pprint import pprint\n",
                "from typing import Literal, Optional, Dict, List, Any\n",
                "from abc import ABC, abstractmethod\n",
                "import math\n",
                "from inspect_ai.model import ChatMessageUser, ChatMessageAssistant, ChatMessageSystem\n",
                "import re\n",
                "from utils import countrylist\n",
                "from utils import evaluate_expression, apply_user_format, apply_assistant_format\n",
                "\n",
                "# Test the function\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1Ô∏è‚É£ Intro to LLM Agents"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## What is an LLM agent?\n",
                "<!---\n",
                "Points to make:\n",
                "- \"LLM agent\" - a \"scaffolding\" program (i.e. Python program) that interacts with an LLM API. Include a version of METR \"Evaluating Language-Model Agents on Realistic Autonomous Tasks\" Figure 2\n",
                "    - Define scaffolding\n",
                "- More schematic breakdown of possible scaffolding: \"tools\" (describe what this means, what \"tool calling\" is), \"memory\" (Probably better move to \"Build Agent\" section! I've expanded this section there)\n",
                "- Mention list of examples of prominent LLM agents:\n",
                "    - [Minecraft LM Agent](https://arxiv.org/abs/2305.16291)\n",
                "    - [AutoGPT](https://autogpt.net/) and [LangChain](https://www.langchain.com/)\n",
                "\n",
                "==========================\n",
                "--->\n",
                "An LLM \"agent\" consists of **a scaffolding program interacting with an LLM API**. Initially, the scaffolding program sends instructions to the LLM on the task goal, the actions available to the LLM, and any relevant task information. The LLM then interacts with the scaffolding program in a sequence of steps, taking actions and observing their results. The scaffolding program will perform any actions or interactions with the task as instructed by the LLM; it will also return the outcome of these actions to the LLM agent. This allows the LLM to solve a task relatively autonomously (i.e. with little human input).\n",
                "\n",
                "The two main elements of scaffolding are:\n",
                "- Tool calling: This provides a description of a tool to the agent, which it can choose to use during the evauation. If it uses a tool then the scaffolding will execute this tool on the agent's behalf (usually consisting of running a python function), and return the result of this tool call to the agent.\n",
                "\n",
                "- Prompting: This is how the task state is described to the LLM. We can also use prompting to help assist the LLM in its tool use, or instruct it to use chain-of-thought to give the LLM more \"thinking time.\" \n",
                "\n",
                "The LLM interacts with scaffolding program to complete a task according to the following steps:\n",
                "\n",
                "1. The LLM receives input (task description, current state, available actions etc.) from the scaffolding program\n",
                "2. The LLM processes the input and outputs an action (e.g. use calculator)\n",
                "4. The scaffolding program executes the action the agent took and returns the outcome (e.g. it would run `calculate()` in the background for an LLM using a calculator, and then return the function output to the agent)\n",
                "5. The LLM receive the results and decides the next action\n",
                "6. Repeating the cycle until the task is complete\n",
                "\n",
                "\n",
                "[Insert METR diagram]\n",
                "\n",
                "Some examples of LLM agents are:\n",
                "\n",
                "- [Voyager](https://arxiv.org/abs/2305.16291) (Minecraft LLM Agent)\n",
                "\n",
                "- [AutoGPT](https://autogpt.net/)\n",
                "\n",
                "- [LangChain](https://www.langchain.com/)\n",
                "\n",
                "\n",
                "<!-- An LLM agent consists of 4 main things [I think a better list exists here, \"reasoning engine\" is quite unclear/vague and scaffolding doesn't make sense as a bullet point in how we've defined it; also maybe move this to start of section \"Build agent?\"].\n",
                "\n",
                "- A 'reasoner' or 'reasoning engine.' (Some people also call this a 'world model'). For LLM agents this is a large language model.\n",
                "\n",
                "- Tools which allow the agent to act in the environment.\n",
                "\n",
                "- Memory so that the agent can recall prior actions. This can either be:\n",
                "\n",
                "    - Short-term memory: In the context of LLM agents this is generally the context window\n",
                "\n",
                "    - Long-term memory: There are many cases where context-windows are too short, and we will need to give the agent high-level information about actions it took a long time ago. There are many methods to store this 'long-term memory' for agents (see some methods [here])\n",
                "\n",
                "- Scaffolding: This is essentially any structure which we provide to the 'reasoning engine' in order to help it to reason better, such as:\n",
                "\n",
                "    - Prompting frameworks.\n",
                "\n",
                "    - The ability to trial plans into the future.\n",
                "\n",
                "    - Using subagents to take care of subtasks.\n",
                "\n",
                "    - Subgoal decomposition.\n",
                "\n",
                "EXCALIDRAW!\n",
                "\n",
                "## How should we evaluate LLM agents?\n",
                "\n",
                "Points to make - \"Why evaluate LLM agents\":\n",
                "- overall note: I think this could heavily be based on this [video](https://www.youtube.com/watch?v=KO72xvYAP-w) from METR\n",
                "- The purpose of agent evals is to **unlock and measure the full capabilities of a model**, to avoid underestimating the model and to better estimate the **ceiling** of their capability and potential to cause harm. \n",
                "- Models often fail in easily-fixable ways. For example, when it is solving a hacking task, it\n",
                "    - Can refuse due to ethics or (claimed) inability \n",
                "    - Can give up and ask the user for help \n",
                "    - Can get stuck in loops \n",
                "    - Can hallucinate facts or conclusions [only partly fixable] \n",
                "    - Can be limited by primitive tools \n",
                "    - Can have bugs\n",
                "    - ...\n",
                "- For a model that fails to solve a hacking task, thus deemed safe, there might exist simple fixes (e.g. better prompts, better file manipulation tools) that unlock this dangerous capability. \n",
                "- \n",
                "- Final point about \"quantifying\" the amount of scaffolding to make eval results more quantitative\n",
                "    - Apollo \"Science of Evals\" \n",
                "    - GDM quantify bits\n",
                "==========================\n",
                "--->\n",
                "## How should we evaluate LLM agents?\n",
                "\n",
                "There are two possible purposes of LLM agent evaluations:\n",
                "\n",
                "- The first is to **unlock and measure the full capabilities of a model**. We don't want to underestimate current or future LLMs, so we want to establish the **ceiling** of their capabilties and potential to cause harm.\n",
                "- The second is to **determine the alignment properties of LLMs in agentic scenarios**. Most of our current alignment techniques (Supervised Fine-tuning, RLHF, ... ) are focused on Chatbot contexts for LLMs, however LLM agents have the potential to cause much greater harm, and we currently aren't as confident about how RLHF and Supervised Fine-tuning will work in these contexts.\n",
                "\n",
                "LLM agents generally fail in easy-to-fix ways, as you will see. For example:\n",
                "\n",
                "- They often claim to be incapable of tasks that they can actually perform.\n",
                "\n",
                "- They can easily get stuck in loops.\n",
                "\n",
                "- They can hallucinate facts, or even misunderstand their own prior reasoning and hallucinate a faulty conclusion.\n",
                "\n",
                "- They can be overly or underly sensitive to information in their prompts.\n",
                "\n",
                "This means that when models fail to accomplish tasks, there may exist simple fixes that will unlock a capability. Since we want to eliminate the potential of large capability improvements from relatively little effort, this means that we have to try quite hard to tune the promptings, tool descriptions, and tool outputs just right, so that we can see LLM agents at their *best*.\n",
                "<!--->\n",
                "Many of our threat models for the future harms of AI systems go through agentic behavior. If we knew that chatbots were only ever capable of simulating continuations of text in their context window, we'd still be worried about them ‚Äî but significantly less. However, we know today that this is not the case. In fact, since the release of ChatGPT, the use of LLMs as reasoning engines for agentic systems has proliferated signficantly. See [AutoGPT](https://autogpt.net/) and [LangChain](https://www.langchain.com/). These agents started off rather disappointingly initially, when they were based on GPT-3.5. However as more powerful LLMs come out and AI companies ensure their LLMs are better at tool-use, these agents are improving rapidly.\n",
                "\n",
                "\n",
                "The main concerns for LLM agents that we want to mitigate are:\n",
                "\n",
                "- Their capabilities may be signficantly greater than those of the base LLM (especially when augmented with tool use).\n",
                "\n",
                "- There are many possible improvements for increased performance from LLM agents, and these improvement methods are often signficantly cheaper and easier to implement than training the base model.\n",
                "\n",
                "- Current fine-tuning and RLHF/Constitutional AI methods are mostly targeted towards chatbot-style text output. We aren't as confident about how such methods will generalize to agentic scenarios.\n",
                "\n",
                "The first two issues here relate to the **capabilities** of LLM agents, and the last issue relates to the **alignment** properties of LLM agents. The agent we'll be building will be testing for the **capability** properties of agents.\n",
                "<!--->\n",
                "\n",
                "<details><summary>Further resources on LLM evaluations:</summary>\n",
                "\n",
                "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
                "\n",
                "- [Anthropic Function Calling Guide](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)\n",
                "\n",
                "- [Evaluating Language-Model Agents on Realistic Autonomous Tasks](https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf) (Kinniment et al., ARC Evaluations Team (now METR), 2023)\n",
                "\n",
                "- [Large Language Models can Strategically Deceive their Users when Put Under Pressure](https://arxiv.org/pdf/2311.07590) (Scheurer et al., Apollo Research, ICLR 2024)\n",
                "\n",
                "- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) (Lilian Weng, OpenAI Safety Team, 2023)\n",
                "\n",
                "- [AXRP Episode 34 - AI Evaluations with Beth Barnes](https://www.alignmentforum.org/posts/vACr4DExfeRMaCoo7/axrp-episode-34-ai-evaluations-with-beth-barnes) (Daniel Filan, 2024)\n",
                "\n",
                "- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/pdf/2303.11366) (Shinn et al., 2023)\n",
                "\n",
                "- [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://arxiv.org/pdf/2304.13007) (Yoran et al., 2024)\n",
                "\n",
                "- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761) (Schick et al., META AI Research, 2023)\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2Ô∏è‚É£ Build a Simple LLM Arithemtic Agent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will start by building a simple LLM agent that solves arithmetic problems. LLMs struggle with arithmetic, but we can drastically improve their performance by providing a simple calculation tool. We'll try the model with and without tools on this task, and see how significantly performance improves.\n",
                "\n",
                "To build this, we will implement 4 things:\n",
                "- The `ArithmeticTask` class handles arithmetic problem generation and solution verification.\n",
                "- The `CalculateTool`, a tool that LLM agents can use to solve the task.\n",
                "- The `ArithmeticAgent` class handles interacting with the LLM API, doing the calculation, and keeping track of the overall task progress.\n",
                "- The `agent_loop()` function defines the interaction loop between the task and the agent to execute the task.\n",
                "\n",
                "In general, ... [description of how to think about designing task and agent in generation, include decision factors] probably good to include a diagram here (or maybe earlier)\n",
                "\n",
                "We build task\n",
                "We build tool\n",
                "\n",
                "We build scaffold\n",
                "We build agent\n",
                "\n",
                "We loop things."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Defining the Task"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build a simple arithmetic problem\n",
                "```c\n",
                "Difficulty: üî¥üî¥üî¥‚ö™‚ö™\n",
                "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
                "\n",
                "You should spend up to 20-25 minutes on this exercise.\n",
                "```\n",
                "\n",
                "In an LLM agent eval, there will usually be a `Task` class, which interacts with the `Agent`. In general, the `Task` class will:\n",
                "\n",
                "- Prepare and provide the task instruction (and necessary files, functions etc) to the agent,\n",
                "\n",
                "- Parse and score the agent's output,\n",
                "\n",
                "- Update the task state accordingly (e.g. proceeds onto the next step of the task, ends the task).\n",
                "\n",
                "We will build a toy task called `ArithmeticTask`. This task takes in two numbers and create a list of arithmetic calculation problems with these two numbers, using arithmetic operations defined in `operations`. It should have methods to do the following:\n",
                "\n",
                "- Get the current problem (e.g. at the start this will be `\"Calculate num1 + num2\"`),\n",
                "\n",
                "- Check if a given answer is correct,\n",
                "\n",
                "- Update the current problem (depending on whether the answer generated by the model was correct),\n",
                "\n",
                "- Check if all problems have been solved,\n",
                "\n",
                "<details><summary>Aside: Handling calculations</summary><br> When we handle the calculations for the model, technically we could use Python's <code>eval()</code> function (this is what <a href = \"https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb\">Anthropic did</a>(!)). However, this function evaluates an arbitrary string expression, and so allows AI models to run arbitrary code. In the long-run, we're trying to do these evaluations on models which we suspect of being dangerous; so even though we could probably trust the current suite of language models offered by OpenAI and Anthropic, we should get into the good habit of not running arbitrary code outputted by language models (except in very carefully set-up environments). To this end, we've implemented an <code>evaluate_expression</code> function for you to use instead. It should already be imported from <code>utils</code>.</details>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "10 + 15 = 25\n",
                        "10 - 15 = -5\n",
                        "10 * 15 = 150\n",
                        "10 / 15 = 0.6666666666666666\n",
                        "10 % 15 = 10\n",
                        "10 // 15 = 0\n"
                    ]
                }
            ],
            "source": [
                "class ArithmeticTask:\n",
                "    def __init__(self, num1: int | float, num2: int | float, tools: list = None):\n",
                "        self.num1 = num1\n",
                "        self.num2 = num2\n",
                "        self.tools = tools\n",
                "        self.operations: List[str] = [\"+\", \"-\", \"*\", \"/\", \"%\", \"//\"]\n",
                "        self.correct_answers: Dict[str, float] = self._generate_answers()\n",
                "        self.is_solved: Dict[str, bool] = {expr: False for expr in self.correct_answers}\n",
                "        self.current_task_number = 0\n",
                "\n",
                "    def _generate_answers(self) -> Dict[str, float]:\n",
                "        return {\n",
                "            f\"{self.num1} {op} {self.num2}\": eval(f\"{self.num1} {op} {self.num2}\")\n",
                "            for op in self.operations\n",
                "        }\n",
                "\n",
                "    def get_current_task(self) -> str:\n",
                "        \"\"\"\n",
                "        Returns the current task as a string\n",
                "        \"\"\"\n",
                "        return f\"{str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}\"\n",
                "\n",
                "    def get_instructions(self) -> str:\n",
                "        \"\"\"\n",
                "        Returns a string containing initial task instructions for the agent.\n",
                "        \"\"\"\n",
                "        return f\"Calculate the result of the following expression: {self.get_current_task()}. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\"\n",
                "\n",
                "    def check_solved(self) -> bool:\n",
                "        \"\"\"\n",
                "        Returns True if all tasks are solved, False otherwise\n",
                "        \"\"\"\n",
                "        return all(self.is_solved.values())\n",
                "\n",
                "    def check_answer(self, model_answer: str) -> bool:\n",
                "        \"\"\"\n",
                "        Returns True if the model_answer is correct, False otherwise\n",
                "        \"\"\"\n",
                "\n",
                "        correct_answer = self.correct_answers[self.get_current_task()]\n",
                "        return math.isclose(\n",
                "            float(model_answer), correct_answer, rel_tol=1e-5, abs_tol=1e-8\n",
                "        )\n",
                "\n",
                "    def update_current_task(self) -> None:\n",
                "        \"\"\"\n",
                "        Sets the current task as solved and updates the current_task_number by one\n",
                "        \"\"\"\n",
                "        self.is_solved[self.get_current_task()] = True\n",
                "        self.current_task_number = (self.current_task_number + 1) % len(self.operations)\n",
                "\n",
                "\n",
                "x = ArithmeticTask(10, 15)\n",
                "for problem, answer in x.correct_answers.items():\n",
                "    print(f\"{problem} = {answer}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Function Calling\n",
                "\n",
                "**Function calling** is a feature of LLM Chat APIs that allows the LLM to use external \"tools\" (i.e. Python functions, APIs) by simply receiving and outputing text. There are 5 simple steps to function calling:\n",
                "\n",
                "1. Pick a function in your codebase that the model should be able to call (in this case, we will pick the function `calculate()` from our task class)\n",
                "\n",
                "2. Describe your function to the model (following the syntax of the model's API) so it knows how to call it\n",
                "\n",
                "3. Pass your function definitions as available ‚Äútools‚Äù to the model, along with the messages (following the syntax of the model's API)\n",
                "\n",
                "4. Receive and handle the model response\n",
                "\n",
                "5. Provide the function call result back to the model \n",
                "\n",
                "Chat models like ChatGPT and Claude are fine-tuned to recognize and respond to `tool` descriptions appropriately (just like `user` and `system` messages). In this way, you can allow LLMs to do complex actions like run code, make calls to other APIs, manipulate files etc. We do this by parsing their response output, executing the functions they've called ourselves, and then feeding the results back into the model so it can reason about them and take the next steps. This function-calling loop is the simplest version of a LLM agent, but more advanced LLM agents follow the same logic (except with more advanced tools and more complex task structures to pemirt more autonomous actions etc.).\n",
                "\n",
                "[DIAGRAM]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Write a tool class for function calling\n",
                "```c\n",
                "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµüîµ‚ö™‚ö™\n",
                "\n",
                "You should spend up to 10 minutes on this exercise.\n",
                "```\n",
                "\n",
                "When writing tools, there will be two methods that need to be defined. The first is the `execute()` function. This should take in an arithmetical expression (e.g. `\"3+5\"`) and output the result of this expression (also as a string).\n",
                "\n",
                "<details><summary>Aside: Handling calculations</summary><br> When we handle the calculations for the model, technically we could use Python's <code>eval()</code> function (this is what <a href = \"https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb\">Anthropic did</a>(!)). However, this function evaluates an arbitrary string expression, and so allows AI models to run arbitrary code. In the long-run, we're trying to do these evaluations on models which we suspect of being dangerous; so even though we could probably trust the current suite of language models offered by OpenAI and Anthropic, we should get into the good habit of not running arbitrary code outputted by language models (except in *very* carefully set-up environments). To this end, we've implemented an <code>evaluate_expression</code> function for you to use instead. It should already be imported from <code>utils</code>.</details>\n",
                "\n",
                "We then need to write the `description` property of our `\"calculator\"` function, so we can give it to our LLM agent as a tool. The syntax may differ between APIs (e.g. the OpenAI API has a different syntax than Anthropic API). Read OpenAI's [function calling guide](https://platform.openai.com/docs/guides/function-calling) to learn the syntax. The `description` property should just return a tool description (in the necessary json format). \n",
                "\n",
                "Therefore your tool should be defined according to the following structure:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Tool:\n",
                "    @abstractmethod\n",
                "    def execute(input: str) -> str: ...\n",
                "\n",
                "    @property\n",
                "    def description(self) -> str: ..."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here are some good practices for writing tool descriptions for Claude (according to Anthropic), they should generalize to other chat models:\n",
                "- Provide extremely detailed descriptions. This is by far the most important factor in tool performance. Your descriptions should explain every aspect of the tool, including:\n",
                "\n",
                "    - What the tool does\n",
                "\n",
                "    - When it should be used (and when it shouldn‚Äôt)\n",
                "\n",
                "    - What each parameter means and how it affects the tool‚Äôs behavior\n",
                "\n",
                "    - Any important caveats or limitations, such as what information the tool does not return if the tool name is unclear. The more context you can give Claude about your tools, the better it will be at deciding when and how to use them. Aim for at least 3-4 sentences per tool description, more if the tool is complex.\n",
                "    \n",
                "- Prioritize descriptions over examples. While you can include examples of how to use a tool in its description or in the accompanying prompt, this is less important than having a clear and comprehensive explanation of the tool‚Äôs purpose and parameters. Only add examples after you‚Äôve fully fleshed out the description.\n",
                "\n",
                "Read Anthropic's examples of what good and bad tool calling looks like [here](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-of-a-good-tool-description). \n",
                "\n",
                "Now write your tool class for the `CalculateTool` below. Inherit from the general `Tool` class defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CalculateTool(Tool):\n",
                "    name = \"calculate\"\n",
                "\n",
                "    @staticmethod\n",
                "    def execute(expression: str) -> str:\n",
                "        \"\"\"\n",
                "        Evaluates the string expression in Python using `evaluate_expression()` and returns the result as a string\n",
                "        \"\"\"\n",
                "        print(\"Expression received:\", expression)\n",
                "        try:\n",
                "            return str(evaluate_expression(expression))\n",
                "        except (SyntaxError, NameError, ZeroDivisionError) as e:\n",
                "            return f\"Error: {str(e)}\"\n",
                "\n",
                "    @property\n",
                "    def description(self):\n",
                "        return {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": self.name,\n",
                "                \"description\": 'Calculates the result of an arithmetic expression. For example, you could provide an input in the form \"2+3\" and the function would return 5. Or you could provide an expression like \"10/3\" and the function would return 3.3333333333333335.',\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"expression\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The arithmetic expression that you want to be evaluated.\",\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"expression\"],\n",
                "                    \"additionalProperties\": False,\n",
                "                },\n",
                "            },\n",
                "        }\n",
                "\n",
                "\n",
                "Calculator = CalculateTool()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary> Aside - What is a @staticmethod?</h2></summary>\n",
                "\n",
                "The `@staticmethod` decorator in Python is used to define a static method within a class. Here are some key points about static methods:\n",
                "1. They don't use instance- or class-specific data, thus does not require a first parameter `self` or `cls`.\n",
                "2. They're often used for utility functions related to the class.\n",
                "\n",
                "In our `ArithmeticTask` class, the `calculate` method is defined as a static method:\n",
                "\n",
                "```python\n",
                "@staticmethod\n",
                "def calculate(expression: str) -> str:\n",
                "    \"\"\"Evaluates the string expression and returns the result as a string.\"\"\"\n",
                "    try:\n",
                "        return str(evaluate_expression(expression))\n",
                "    except (SyntaxError, NameError, ZeroDivisionError) as e:\n",
                "        return f\"Error: {str(e)}\"\n",
                "```\n",
                "\n",
                "This can be called on the class itself without creating an instance:\n",
                "\n",
                "   ```python\n",
                "   result = ArithmeticTask.calculate(\"2 + 3\")\n",
                "   ```\n",
                "\n",
                "You can also call it on an instance of the class, but this is not the convention because it doesn't utilize the instance in any way (it doesn't have access to `self`):\n",
                "   ```python\n",
                "   problem = ArithmeticTask(10, 15)\n",
                "   result = problem.calculate(\"2 + 3\")\n",
                "   ```\n",
                "\n",
                "Typically, you would make \"stand-alone\" functions that do not depend on class methods or class/instance attributes a static method. Using `@staticmethod` in this case:\n",
                "1. Makes the code's intent clearer (this method doesn't need class or instance data).\n",
                "2. Slightly improves performance (no `self` argument needs to be passed).\n",
                "3. Allows the method to be used without creating an instance of the class.\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can include the tool description in the API call simply by giving it as an arg to `tools` (the description has to be in a list, as the `create()` function's `tools` argument only accepts lists of tool descriptions): "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "None\n",
                        "[ChatCompletionMessageToolCall(id='call_UOdJVFhWByYTKOVJC4AS1Xpi', function=Function(arguments='{\"expression\":\"2+3\"}', name='calculate'), type='function')]\n"
                    ]
                }
            ],
            "source": [
                "messages = [{\"role\": \"user\", \"content\": \"Calculate 2+3\"}]\n",
                "client = establish_client_OpenAI()\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=\"gpt-4o-mini\",\n",
                "    messages=messages,\n",
                "    tools=[Calculator.description],\n",
                "    tool_choice=\"auto\",\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)\n",
                "print(response.choices[0].message.tool_calls)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary>Why is <code>message.content = None</code>?</summary>\n",
                "\n",
                "When the LLM's use tools, they often don't generate any text output. This can be a problem later when you try to get the model to do chain-of-thought reasoning. To get around this, often it's better to make two calls to the model for more complex tool use: one call to get the model to reason about the actions it should take, and then another to get the model to use a tool to take those actions.\n",
                "\n",
                "</details> "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Return tool call results to the model\n",
                "```c\n",
                "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµüîµ‚ö™‚ö™\n",
                "\n",
                "You should spend up to 10-15 minutes on this exercise.\n",
                "```\n",
                "\n",
                "In order to return the response of tools to OpenAI LLMs, you'll need to add **two** items to the `messages` list after the model has made a tool call in a `ChatCompletionMessage` output:\n",
                "1. The `ChatCompletionMessage` object itself (containing the original tool call message generated by the model). \n",
                "\n",
                "2. The tool response (containing the results of the tool call), in a specific format.\n",
                "\n",
                "Each tool response has to respond to a specific tool call in a `ChatCompletionMessage`, and if we ever try to get the model to generate a response with an unanswered tool call in `messages`, the API will raise an error.\n",
                "\n",
                "Below is the typical `response.choices[0]` output you will being generated by `chat.completions.create()`. The ChatCompletionMessage is accessed via `response.choices[0].message`. You can access the tool calls via `response.choices[0].tool_calls`, which will return a list of `ChatCompletionMessageToolCall` objects.\n",
                "\n",
                "```python\n",
                "Choice(\n",
                "    finish_reason=\"tool_calls\",\n",
                "    index=0,\n",
                "    logprobs=None,\n",
                "    message=chat.completionsMessage(\n",
                "        content=None,\n",
                "        role=\"assistant\",\n",
                "        function_call=None,\n",
                "        tool_calls=[\n",
                "            chat.completionsMessageToolCall(\n",
                "                id=\"call_62136354\",\n",
                "                function=Function(arguments='{\"expression\":\"2+3\"}', name=\"calculate\"),\n",
                "                type=\"function\",\n",
                "            )\n",
                "        ],\n",
                "    ),\n",
                ")\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have provided a function that formats the tool response in the correct syntax to be returned to the model. Read the format to understand what it looks like (you do not need to memorize this as you can always find it on OpenAI's [function calling guide](https://platform.openai.com/docs/guides/function-calling).)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "def apply_tool_call_format(\n",
                "    tool_call: ChatCompletionMessageToolCall, content: str\n",
                ") -> dict:\n",
                "    \"\"\"\n",
                "    Formats the response of a tool call to be returned to the model.\n",
                "    Args:\n",
                "        - tool_call : ChatCompletionMessageToolCall\n",
                "        - content : str - This is the tool response (i.e. results from executing the tool)\n",
                "    \"\"\"\n",
                "    return {\n",
                "        \"role\": \"tool\",\n",
                "        \"tool_call_id\": tool_call.id,\n",
                "        \"name\": tool_call.function.name,\n",
                "        \"content\": content,  # e.g. \"5\"\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we can generate a message and return the tool call response to the model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Expression received: 5/3\n",
                        "The precise result of \\( 5/3 \\) is approximately 1.6666666666666667.\n"
                    ]
                }
            ],
            "source": [
                "messages = [{\"role\": \"user\", \"content\": \"Calculate 5/3. Be precise.\"}]\n",
                "response = client.chat.completions.create(\n",
                "    model=\"gpt-4o-mini\",\n",
                "    messages=messages,\n",
                "    tools=[Calculator.description],\n",
                "    tool_choice=\"auto\",\n",
                ")\n",
                "\n",
                "messages.extend(\n",
                "    [\n",
                "        response.choices[0].message,\n",
                "        apply_tool_call_format(\n",
                "            response.choices[0].message.tool_calls[0],\n",
                "            Calculator.execute(\n",
                "                json.loads(\n",
                "                    response.choices[0].message.tool_calls[0].function.arguments\n",
                "                )[\"expression\"]\n",
                "            ),\n",
                "        ),\n",
                "    ]\n",
                ")\n",
                "\n",
                "response_to_tool_calls = client.chat.completions.create(\n",
                "    model=\"gpt-4o-mini\",\n",
                "    messages=messages,\n",
                "    tools=[Calculator.description],\n",
                "    tool_choice=\"auto\",\n",
                ")\n",
                "print(response_to_tool_calls.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Building the Agent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Most LLM agents share these core components:\n",
                "\n",
                "1. **LLM API interface**: A basic function (e.g. `get_response()`) that makes the API calls to the LLM and return its responses.\n",
                "\n",
                "2. **Actions**: A set of actions (i.e. functions) the agent can take.\n",
                "\n",
                "3. **Task State Management**: Keeping track of the current state of the task and any relevant context.\n",
                "\n",
                "4. **Memory**: A system for storing and retrieving relevant information from past interactions (i.e. chat history). The simplest implemention is usually a `self.history` class attribute that stores a list of past chat messages.\n",
                "\n",
                "5. **Observation Parser**: Functions to parse and interpret the results of actions and update the state.\n",
                "\n",
                "6. **Decision/Execution Logic**: The rules or algorithms used to choose actions based on the current state and LLM output.\n",
                "\n",
                "7. **Task-Specific Information**: Any additional information or functions specific to the task at hand.\n",
                "\n",
                "[Diagram]\n",
                "\n",
                "We will first implement a `SimpleAgent` class that is not specific to the `ArithmeticTask`, so that we can see the key components of an generic LLM agent."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement `SimpleAgent`\n",
                "```c\n",
                "Difficulty: üî¥üî¥üî¥üî¥‚ö™\n",
                "Importance: üîµüîµüîµüîµüîµ\n",
                "\n",
                "You should spend up to 20-25 minutes on this exercise.\n",
                "```\n",
                "\n",
                "Build out the following simple agent class by filling in `get_response()` and `execute_tool_calls()` functions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleAgent(ABC):\n",
                "    def __init__(\n",
                "        self,\n",
                "        task=None,\n",
                "        model: Literal[\"gpt-4o-mini\"] = \"gpt-4o-mini\",\n",
                "        history: List[dict] = [],\n",
                "    ):\n",
                "        self.model = model\n",
                "        self.task = task\n",
                "        self.tools = task.tool_list if task else None\n",
                "        self.client = OpenAI()\n",
                "        self.history = history\n",
                "\n",
                "    @retry_with_exponential_backoff\n",
                "    def get_response(self, use_tool: bool = True) -> ChatCompletionMessage:\n",
                "        \"\"\"\n",
                "        Get the response from the model via an API call, with the option of tool calling.\n",
                "        \"\"\"\n",
                "        response = self.client.chat.completions.create(\n",
                "            model=self.model,\n",
                "            messages=self.history,\n",
                "            tools=[tool.description for tool in self.tools] if use_tool else None,\n",
                "            tool_choice=\"auto\" if use_tool else None,\n",
                "        )\n",
                "        return response.choices[0].message\n",
                "\n",
                "    def execute_tool_calls(self, message: ChatCompletionMessage) -> List[str]:\n",
                "        \"\"\"\n",
                "        Execute the tool calls in the message and return a list of tool_responses.\n",
                "        \"\"\"\n",
                "        tool_calls = message.tool_calls\n",
                "        print(\"\\nModel tool calls:\\n\", tool_calls)\n",
                "\n",
                "        tool_responses = []\n",
                "        for tool_call in tool_calls:\n",
                "            if not self.task:\n",
                "                raise ValueError(\"Task is not set. Cannot execute tool calls.\")\n",
                "            func = getattr(self.task, tool_call.function.name)\n",
                "            arguments = json.loads(tool_call.function.arguments)\n",
                "            tool_response = func(**arguments)\n",
                "            tool_responses.append(tool_response)\n",
                "\n",
                "        return tool_responses\n",
                "\n",
                "    def run(self, task: Any, with_tool: bool = True):\n",
                "        \"\"\"\n",
                "        Default implementation of run method.\n",
                "        This can be overridden in subclasses for specific behavior.\n",
                "        \"\"\"\n",
                "        self.task = task\n",
                "        print(f\"Running SimpleAgent...\")\n",
                "        instruction = self.task.get_instructions()\n",
                "        self.history.append(apply_user_format(instruction))\n",
                "        response = self.get_response(use_tool=with_tool)\n",
                "        return response"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "ArithmeticTask.__init__() missing 1 required positional argument: 'tools'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m my_simple_agent \u001b[38;5;241m=\u001b[39m SimpleAgent()\n\u001b[1;32m----> 2\u001b[0m my_simple_agent\u001b[38;5;241m.\u001b[39mrun(\u001b[43mArithmeticTask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Try execute the tool calls\u001b[39;00m\n",
                        "\u001b[1;31mTypeError\u001b[0m: ArithmeticTask.__init__() missing 1 required positional argument: 'tools'"
                    ]
                }
            ],
            "source": [
                "my_simple_agent = SimpleAgent()\n",
                "my_simple_agent.run(ArithmeticTask(10, 15))\n",
                "\n",
                "# Try execute the tool calls\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build an `ArithmeticAgent`\n",
                "```c\n",
                "Difficulty: üî¥üî¥üî¥üî¥‚ö™\n",
                "Importance: üîµüîµüîµüîµüîµ\n",
                "\n",
                "You should spend up to 20-25 minutes on this exercise.\n",
                "```\n",
                "\n",
                "Add instructions here:\n",
                "1. work out the decision tree of the task for ~10min; we give a half-filled task tree, then the full task tree in a drop down\n",
                "2. write `run()` - they will implement everything after \"# Handle the response\" in run(); we will give them parse_answer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 250,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ArithmeticAgent(SimpleAgent):\n",
                "    \"\"\"\n",
                "    ArithmeticAgent class for doing simple arithmetic tasks.\n",
                "\n",
                "    Inherits from SimpleAgent and includes the following attributes and methods:\n",
                "\n",
                "    Attributes:\n",
                "        model (str): The model used for generating responses (inherited)\n",
                "        tool_descriptions (List[dict]): List of tool descriptions (inherited)\n",
                "        client (OpenAI): OpenAI client for API calls (inherited)\n",
                "        task (Any): The current task being executed (inherited)\n",
                "        num_tries (int): Number of tries allowed for each action (inherited)\n",
                "        history (List[dict]): History of interactions (inherited)\n",
                "\n",
                "    Methods:\n",
                "        get_response(use_tool: bool = True) -> ChatCompletionMessage: \n",
                "            Get response from the model (inherited)\n",
                "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]: \n",
                "            Execute tool calls from the model's response (inherited)\n",
                "        run(task: 'WikiGame', with_tool: bool = True) -> bool: \n",
                "            Run one loop of the Wikipedia agent\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, model: Literal['gpt-4o-mini'] = \"gpt-4o-mini\", tools: list = tool_list):\n",
                "        super().__init__(model=model, tools=tools)\n",
                "\n",
                "        # Add any ArithmeticTask-specific initialization here\n",
                "        self.num_tries = 3\n",
                "        \n",
                "    \n",
                "    def run(self, task: ArithmeticTask, tools: list, with_tool: bool):\n",
                "        \"\"\"Run one loop of the agent, which involves:\n",
                "            - getting a task\n",
                "            - getting a response from the model\n",
                "            - handling the model response, including tool calls, refusals, no tool calls, parsing and checking final answers, errors.\n",
                "            - managing memory: storing the history of messages to self.history\n",
                "            - managing task state: staying on the same task or moving to the next task at the end of the loop\n",
                "            \"\"\"\n",
                "\n",
                "        self.task = task\n",
                "        \n",
                "        # Get a task instruction\n",
                "        instruction = self.task.get_instructions()\n",
                "        print(\"\\nUSER:\\n\", instruction)\n",
                "        self.history.append(apply_user_format(instruction))\n",
                "\n",
                "        # Get the response from the model\n",
                "        response = self.get_response(use_tool = with_tool)\n",
                "\n",
                "        # Handle the response\n",
                "        ## If tool calls, do the tool calls and return the response \n",
                "        if response.tool_calls:\n",
                "            \n",
                "            # Append the original function calls to the conversation\n",
                "            self.history.append(response)\n",
                "\n",
                "            # Execute the tool calls\n",
                "            tool_responses = self.execute_tool_calls(response)\n",
                "\n",
                "            # Handle tool responses\n",
                "            for tool_call, tool_response in zip(response.tool_calls, tool_responses):\n",
                "                self.history.append(apply_tool_call_format(tool_call, tool_response))\n",
                "            \n",
                "            # Call the model again answer the question with the tool response\n",
                "            response = self.get_response(use_tool = with_tool)\n",
                "            self.history.append(apply_assistant_format(response.content))\n",
                "            print(\"\\nModel response:\\n\", response.content)\n",
                "            \n",
                "            # Check the answer\n",
                "            try:\n",
                "                model_answer = self.parse_answer(response)\n",
                "                \n",
                "                if self.task.check_answer(model_answer):\n",
                "                    self.history.append(apply_assistant_format(\"Correct.\"))\n",
                "                    print(\"\\nUser:\\n Correct.\")\n",
                "                    # Update to the next task\n",
                "                    self.task.update_current_task()\n",
                "                else:\n",
                "                    self.history.append(apply_assistant_format(\"Incorrect.\"))\n",
                "                    print(\"\\nUser:\\n Incorrect.\")\n",
                "                    # Retry the task\n",
                "                    self.num_tries -= 1\n",
                "                    if self.num_tries == 0:\n",
                "                        # Update to next task\n",
                "                        self.task.update_current_task()\n",
                "\n",
                "            # Ends the task if there's an error parsing the model answer\n",
                "            except Exception as e:\n",
                "                print(\"\\nError parsing model answer:\", e)\n",
                "                raise             \n",
                "        \n",
                "        ## If no tool call: Handle edge cases\n",
                "        ### Check if there's a refusal to answer:\n",
                "        elif response.refusal:\n",
                "            print(\"\\nModel Refusal:\\n\", response.refusal)\n",
                "            self.history.append(apply_assistant_format(response.refusal))\n",
                "            # Go to next task\n",
                "            self.task.update_current_task()\n",
                "        \n",
                "        ### Else finish_reason is \"stop\", in which case the model was just responding directly to the user without tool calls\n",
                "        elif response.finish_reason == \"stop\":\n",
                "            self.history.append(apply_user_format(\"You did not use the tool to answer the question. Please use the tool to answer the question.\"))\n",
                "            print(\"\\nModel response:\\n\", response.content)\n",
                "            print(\"\\nUser:\\n You did not use the tool to answer the question. Please use the tool to answer the question.\")\n",
                "\n",
                "\n",
                "    def parse_answer(self, message: ChatCompletionMessage) -> ChatCompletionMessage:\n",
                "        \"\"\"\n",
                "        Extract the numerical answer from the string output of the model \n",
                "        \"\"\"\n",
                "        response = message.content\n",
                "        if response.find(\"<answer>\") != -1:\n",
                "            startpoint = response.find(\"<answer>\") + 8\n",
                "            endpoint = response.find(\"</answer>\")\n",
                "            return float(response[startpoint:endpoint])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Execute the task via an agent_loop \n",
                "```c\n",
                "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµüîµüîµ‚ö™\n",
                "\n",
                "You should spend up to 5-10 minutes on this exercise.\n",
                "```\n",
                "\n",
                "Try implementing the agent_loop below with and without tools, to see how much better the model does when we give it tools."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "metadata": {},
            "outputs": [],
            "source": [
                "task = ArithmeticTask(1500,1091)\n",
                "agent = ArithmeticAgent()\n",
                "\n",
                "def agent_loop(num_loops : int = 10):\n",
                "  \n",
                "    for i in range(num_loops):\n",
                "        if not task.check_solved():\n",
                "            agent.run(task, tool_list, with_tool = True)\n",
                "        else:\n",
                "            print(\"\\nAll tasks solved.\")\n",
                "            break\n",
                "\n",
                "agent_loop()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can print all the messages from the `ChatHistory` as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for message in agent.messages:\n",
                "    try: print(str(message.content))\n",
                "    except: print(message[\"content\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3Ô∏è‚É£ Building a More Complex Task: WikiGame\n",
                "\n",
                "Now that we know how to do function calling and how to design an LLM agent in general, we will build a more complicated task. This task won't be instantly solvable by LLMs with simple tool use and will require us to elicit better capabilities from models.\n",
                "\n",
                "The task we will build and elicit behavior for will be the [Wikipedia Game](https://en.wikipedia.org/wiki/Wikipedia:Wiki_Game): Players use wiki-links to travel from one Wikipedia page to another and the first person who reaches the destination page wins the race. This is not directly related to any dangerous capabilities, and if GPT-N $_{+1}$ could do this task, but GPT-N couldn't, we wouldn't tell OpenAI to be particularly careful about the release of GPT-N $_{+1}$ as a result. However, it makes a useful test case for elicitation methods, since there are many strategies for deciding what path to take and we can create a scale of difficulty by choosing different articles to navigate to/from.\n",
                "\n",
                "To add:\n",
                "- Description of MVP Goal\n",
                "- EXCALIDRAW! (describing wikipedia game.)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Quick Intro to the Wikipedia API"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Our agent will interact with Wikipedia by making tool calls to the [Wikipedia API](https://wikipedia.readthedocs.io/en/latest/quickstart.html), which is simple to use. We will only need to learn the following key functions for the game. \n",
                "\n",
                "1. `wikipedia.page` - Returns a Wikipedia page object, whcih contains various attributes adn methods to access page content. (See [page docs](https://wikipedia-api.readthedocs.io/en/latest/API.html#wikipediapage) for these attributes.)\n",
                "2. `wikipedia.page.title` - Returns the title of the page\n",
                "3. `wikipedia.page.contents` - Returns the full text content of the page (this can be very long, make sure to take snippets when you can as to not use up the context length of the LLM)\n",
                "4. `wikipedia.page.summary` - Returns a summary of the page (i.e. all the text before the first section of the Wikipage)\n",
                "5. `wikipedia.page.links` - Returns a list of all links as strings\n",
                "\n",
                "Kwargs:\n",
                "- `auto_suggest` - let Wikipedia find a valid page title for the query\n",
                "- `redirect` - allow redirection without raising RedirectError\n",
                "\n",
                "Refer to the [docs](https://wikipedia-api.readthedocs.io/en/latest/API.html#) for more information. \n",
                "Now run the following code to see how this works!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Retrieve a Wikipedia page\n",
                "page = wikipedia.page(\"Python (programming language)\")\n",
                "\n",
                "# Access basic page information\n",
                "print(\"Title:\", page.title)\n",
                "print(\"URL\", page.url)\n",
                "print(f\"\\nSummary (word count {len( page.summary.split())}):\", page.summary)\n",
                "print(f\"\\nContent (word count {len( page.content.split())}):\", page.content[:500], \"......\")\n",
                "print(f\"\\nLinks (link count {len( page.links)}):\", page.links[:50], \"......\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now run these two lines (you should see different errors):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {},
            "outputs": [],
            "source": [
                "page = wikipedia.page(\"Python\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "page = wikipedia.page(\"Animalss\", auto_suggest=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [],
            "source": [
                "page = wikipedia.page(\"Animalss\", auto_suggest=True)\n",
                "page.title\n",
                "# TODO: Explain auto_suggest + redirect; not sure what's the difference between auto_suggest and redirect; add an aside on this, and if they are True or False by default"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above code gives a `DisambiguationError` because the title \"Python\" can correspond to multiple pages. We have implemented for you a simple function `get_page` for getting the page object for a particular page title. This handles `DisambiguationError` (when a page title could refer to multiple pages, we choose the first option) and `PageError` (when a page is not found, we...). \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_page(title : str) -> WikipediaPage:\n",
                "    try: \n",
                "        return wikipedia.page(title,auto_suggest=False,redirect=True)\n",
                "    except DisambiguationError as e:\n",
                "        return wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n",
                "    except PageError as e:\n",
                "        return wikipedia.page(title, auto_suggest=True, redirect=True)\n",
                "\n",
                "def get_word_count(text : str) -> int:\n",
                "    return len(text.split())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the Wiki page on \"List of countries and dependencies by population\"\n",
                "title = \"List of countries and dependencies by population\"\n",
                "\n",
                "wikipedia_page = get_page(title) # Experiment with different values for auto_suggest and redirect when using the agent. See what happens\n",
                "print(\"Word count:\", get_word_count(wikipedia_page.content))\n",
                "print(wikipedia_page.content)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<details><summary> Aside: Wikipedia API content can be weird </summary>\n",
                "\n",
                "The wikipedia API often outputs content in unintuitive ways. For example, articles that are essentially just a big list become near useless, since the content omits the list (for example, see the wikipedia API content for <a href = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\">List of countries and dependencies by population</a>). This is fine for our purposes, as these list articles are often banned in wikipedia racing anyway. But this is why it's important to determine what content the wikipedia API accesses ‚Äî anfd why you want to make sure you're testing a large diversity of wikipedia articles.\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Get permitted links from a wikipedia page\n",
                "```c\n",
                "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "When you get the links from a page using `page.links`, this includes links that are not in the main page content (e.g. \"create account\" links, links in footnotes etc.), which are either irrelevant or not permitted by the rules of Wikirace. Write a simple function `get_permitted_links` function, that only return links that are inside the main content. The resulting list of permitted links should be about a third as long as the list of links from the wikipedia API (with more variance for shorter articles as you would expect). This exercise is mainly meant to help you familiarize yourself with using the wikipedia API. \n",
                "\n",
                "<!-- When writing this function, if you manage to get the links in a very effective way, then do that. But remember that Wikipedia is written by a large number of different contributors, often adhering to inconsistent stylings (especially for smaller articles). We just need to get something that **works well enough**. Put more time into doing this effectively if you want at the end, but as soon as something plausibly works, you should move on.\n",
                "\n",
                "<img src=\"https://imgs.xkcd.com/comics/code_lifespan_2x.png\" width=\"400px\" style = \"margin-left: auto; margin-right: auto;display:block\"></img> -->"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_permitted_links(current_page : WikipediaPage) -> list[str]:\n",
                "    \"\"\"\n",
                "    Get \"permitted\" links (i.e. links that are in the content of the page) from a Wikipedia page.\n",
                "    \"\"\"\n",
                "    all_links = current_page.links\n",
                "    content = current_page.content\n",
                "    permitted_links = [link for link in all_links if link in content]\n",
                "    return permitted_links"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, we've implemented a `get_content` function, which the agent will use to get the content of a Wikipedia page. This wraps all the texts that correspond to links in `<link></link>` tags (since otherwise they are presented as strings and indistinguishable from normal text.). \n",
                "\n",
                "TODO: This needs to be fixed! Currently returning weird output. \n",
                "\n",
                "<details><summary>Why not just use `page.links` to get a list of links directly?</summary>\n",
                "\n",
                "We don't just present a list of the accessible links, as this is not very faithful to the wikipedia game. The agent does perform better if we just give it a list of links (as it generally has a rough idea of what links will be accessible from future pages), but the task of parsing the content of wikipedia pages and isolating the most important links is where the majority of the challenge of the wikipedia game comes from:)\n",
                "\n",
                "</details>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_content(page : WikipediaPage) -> str:\n",
                "    content = page.content\n",
                "    permitted_links = get_permitted_links(page)\n",
                "    for word in sorted(permitted_links, key=len, reverse = True):\n",
                "        content = re.sub(\" \" + word + \" \", \" \" + f\"<link>{word}</link>\" + \" \", content, flags = re.I)\n",
                "        content = re.sub(\" \" + word + \",\", \" \" + f\"<link>{word}</link>\" + \",\", content, flags=re.I)\n",
                "        content = re.sub(\" \" + word + \".\", \" \" + f\"<link>{word}</link>\" + \".\", content, flags=re.I)\n",
                "        content = re.sub(\"\\(\" + word + \"\\)\", \"(\" + f\"<link>{word}</link>\" + \")\", content, flags = re.I)\n",
                "        content = re.sub(\" \" + word + \"s\", \" \" + f\"<link>{word}</link>\" + \"s\", content, flags = re.I)\n",
                "    return content\n",
                "\n",
                "wiki_page = get_page(\"Python (programming language)\")\n",
                "get_content(wiki_page)[:500]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build `WikiGame`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build a class for the Wiki game\n",
                "```c\n",
                "Difficulty: üî¥üî¥üî¥üî¥‚ö™\n",
                "Importance: üîµüîµüîµüîµ‚ö™\n",
                "\n",
                "You should spend up to 25-30 mins on this exercise.\n",
                "```\n",
                "\n",
                "Implement the following class that instantiates the wikipedia game. When the model uses tools it will be making calls to this class, so make sure that the functions return messages you're happy for the model to see as a tool response, such as error messages if the tool doesn't work.\n",
                "\n",
                "Use code from the `get_permitted_links` and `get_content` functions above in this class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 259,
            "metadata": {},
            "outputs": [],
            "source": [
                "class BaseWikiGame:\n",
                "    def __init__(self, starting_page: str, goal_page: str, rules: Optional[List[Dict[str, str]]] = None):\n",
                "        \"\"\"\n",
                "        Initialize the Wikipedia game object.\n",
                "\n",
                "        Args:\n",
                "            starting_page (str): The page the agent starts on.\n",
                "            goal_page (str): The page the agent is trying to reach.\n",
                "            rules (Optional[List[Dict[str, str]]]): Additional rules for the game.\n",
                "                Supported rules:\n",
                "                - \"no country\": Bans country articles.\n",
                "                - \"no backtrack\": Bans backtracking.\n",
                "        \"\"\"\n",
                "        self.page_history: List[str] = [starting_page]\n",
                "        self.starting_page: WikipediaPage = self.get_page(starting_page)\n",
                "        self.goal_page: WikipediaPage = self.get_page(goal_page)\n",
                "        self.rules: Optional[List[Dict[str, str]]] = rules\n",
                "        self.current_page: WikipediaPage = self.starting_page\n",
                "\n",
                "    # ========================= Helper Functions (given) =========================\n",
                "    # Get page and page summary\n",
                "    @staticmethod\n",
                "    def get_page(title : str) -> WikipediaPage:\n",
                "        \"\"\"\n",
                "        Get a Wikipedia page object by the title.\n",
                "        \"\"\"\n",
                "        try: \n",
                "            return wikipedia.page(title,auto_suggest=False,redirect=True)\n",
                "        except DisambiguationError as e:\n",
                "            return wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n",
                "        except PageError as e:\n",
                "            return wikipedia.page(title, auto_suggest=True, redirect=True)\n",
                "\n",
                "    @staticmethod\n",
                "    def get_page_summary(page : WikipediaPage) -> str:\n",
                "        \"\"\"\n",
                "        Get summary of a wikipedia page, to the last full stop within the first 500 characters.\n",
                "        \"\"\"\n",
                "        summary = page.content[:500]\n",
                "        last_period_index = summary.rfind('.')\n",
                "        return summary[:last_period_index + 1] if last_period_index != -1 else summary\n",
                "\n",
                "    # Get current page content\n",
                "    def get_content(self) -> str:\n",
                "        '''\n",
                "        Gives the content of the wikipedia page. Make sure that accessible links are wrapped with <link> </link> tags.\n",
                "        '''\n",
                "        content = self.current_page.content\n",
                "        for word in sorted(self.get_permitted_links(), key=len, reverse = True):\n",
                "            content = re.sub(\" \" + word + \" \", \" \" + f\"<link>{word}</link>\" + \" \",content, flags = re.I)\n",
                "            content = re.sub(\" \" + word + \",\", \" \" + f\"<link>{word}</link>\" + \",\", content, flags=re.I)\n",
                "            content = re.sub(\" \" + word + \".\", \" \" + f\"<link>{word}</link>\" + \".\", content, flags=re.I)\n",
                "            content = re.sub(\"\\(\" + word + \"\\)\", \"(\" + f\"<link>{word}</link>\" + \")\", content, flags = re.I)\n",
                "            content = re.sub(\" \" + word + \"s\", \" \" + f\"<link>{word}</link>\" + \"s\", content, flags = re.I)\n",
                "        return content\n",
                "\n",
                "    # Get and check permitted links\n",
                "    def get_permitted_links(self, title: Optional[str] = None) -> list[str]:\n",
                "        \"\"\"\n",
                "        Returns a list of permitted links (i.e. links in the main page content) for the current page.\n",
                "        \"\"\"\n",
                "        if title:\n",
                "            page = self.get_page(title)\n",
                "            all_links = page.links\n",
                "            content = page.content\n",
                "            permitted_links = [link for link in all_links if link in content]\n",
                "        else:\n",
                "            all_links = self.current_page.links\n",
                "            content = self.current_page.content\n",
                "            permitted_links = [link for link in all_links if link in content]\n",
                "        return permitted_links\n",
                "\n",
                "    def is_permitted_link(self, link : str) -> bool:\n",
                "        \"\"\"\n",
                "        Returns True if the link is in the permitted links for the current page, False otherwise.\n",
                "        \"\"\"\n",
                "        return link.lower() in (x.lower() for x in self.get_permitted_links())\n",
                "\n",
                "\n",
                "    # ========================= Task State Management (to implement) =========================\n",
                "\n",
                "    @property\n",
                "    def start_instruction(self) -> dict:\n",
                "        \"\"\"\n",
                "        Generate the start instructions for the game.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\" : \"system\", \n",
                "            \"content\" : f\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from a series of wikipedia pages. Your current page is {self.current_page.title}.\"\n",
                "            }\n",
                "\n",
                "    @property\n",
                "    def on_page_instruction(self) -> dict:\n",
                "        \"\"\"\n",
                "        Generate instructions for the current page.\n",
                "        \"\"\"\n",
                "        return {\n",
                "            \"role\" : \"user\", \n",
                "            \"content\" : f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary: \n",
                "            \n",
                "            [Begin Summary]\n",
                "            {self.get_page_summary(self.goal_page)}\n",
                "            [End Summary]\"\"\"\n",
                "            }\n",
                "    \n",
                "    @property\n",
                "    def next_step_instruction(self) -> dict:\n",
                "        return {\n",
                "            \"role\" : \"user\", \n",
                "            \"content\" : f\"What's your next step to get to {self.goal_page.title}?\"\n",
                "            }\n",
                "\n",
                "    def get_instructions(self, system: bool, on_page: bool, next_step: bool) -> str:\n",
                "        \"\"\"\n",
                "        Generate instruction messages based on the current game state.\n",
                "        \"\"\"\n",
                "        messages = []\n",
                "        if system:\n",
                "            messages.append(self.start_instruction)\n",
                "        if on_page:\n",
                "            messages.append(self.on_page_instruction)\n",
                "        if next_step:\n",
                "            messages.append(self.next_step_instruction)\n",
                "        return messages\n",
                "\n",
                "\n",
                "    def move_page(self, new_page: str) -> str:\n",
                "        \"\"\"\n",
                "        Changes the current page of the game. To be used when we want to move from Page A to Page B\n",
                "        \"\"\"\n",
                "        new_page_lower = new_page.lower()\n",
                "        new_page_normalized = new_page.replace(\"_\", \" \")\n",
                "\n",
                "        if self.is_permitted_link(new_page_lower) or self.is_permitted_link(new_page_normalized):\n",
                "            self.current_page = self.get_page(new_page_normalized)\n",
                "            self.page_history.append(self.current_page.title)\n",
                "            return f\"Moving page to {self.current_page.title}\"\n",
                "        else:\n",
                "            return f\"Couldn't move page to {new_page}. This is not a valid link.\"\n",
                "\n",
                "    def check_win(self) -> bool:\n",
                "        return self.current_page == self.goal_page\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build tools for Wiki game\n",
                "```c\n",
                "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµüîµ‚ö™‚ö™\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "Fill in the following list of tools that the agent will need to use to accomplish this game. You should name the tools according to the names in the `WikiGame` class above. This will help us later when we write the code for the agent, as it will be easier for us to execute the correct tool.\n",
                "\n",
                "When formatting this tool list, refer back to the tools you wrote for the arithmetic game, or else the docs are [here](https://platform.openai.com/docs/guides/function-calling)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_content_tool = {\n",
                "    \"type\" : \"function\",\n",
                "    \"function\" : {\n",
                "        \"name\" : \"get_content\",\n",
                "        \"description\" : \"Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select will be wrapped in <link></link> tags.\",\n",
                "        \"parameters\" : {\n",
                "            \"type\" : \"object\",\n",
                "            \"properties\" : {},\n",
                "            \"required\" : []\n",
                "        }\n",
                "    }\n",
                "}\n",
                "\n",
                "move_page_tool = {\n",
                "    \"type\" : \"function\",\n",
                "    \"function\" : {\n",
                "        \"name\" : \"move_page\",\n",
                "        \"description\" : \"Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\",\n",
                "        \"parameters\": {\n",
                "            \"type\": \"object\",\n",
                "            \"properties\": {\n",
                "                \"new_page\": {\n",
                "                    \"type\": \"string\",\n",
                "                    \"description\": \"The title of the new page you want to move to. This should be formatted the way the title appears on wikipedia (e.g. to move to the wikipedia page for the United States of America, you should enter \\\"United States\\\"). Underscores are not necessary.\",\n",
                "                },\n",
                "            },\n",
                "            \"required\": [\"new_page\"]\n",
                "        }\n",
                "    }\n",
                "}\n",
                "\n",
                "wiki_game_tools = [get_content_tool, move_page_tool]\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Build a WikiAgent\n",
                "```c\n",
                "üî¥üî¥üî¥üî¥‚ö™\n",
                "üîµüîµüîµüîµüîµ\n",
                "\n",
                "You should spend up to 30-40 mins on this exercise.\n",
                "```\n",
                "\n",
                "\n",
                "Insturctions to give:\n",
                "1. again, work out task decision tree \n",
                "2. let them implement handle_tool_call(), run(), start()\n",
                "\n",
                "===================\n",
                "\n",
                "Now that you have the `WikiGame` class and tools set up, build out a `WikiAgent` that can access these tools and solve the Wikipedia game. Build the agent so that it can be thrown into an agent loop (similar to the one we had for the arithmetic game) without much additional scaffolding. \n",
                "\n",
                "There are a few further considerations in this case that we didn't have for the arithmetic game. \n",
                "\n",
                "<details>\n",
                "<summary>Context window considerations</summary>\n",
                "\n",
                "Since the agent will need to read (potentially very long) Wikipedia articles to interact with the game, the length of the context window becomes relevant. GPT-4o and GPT-4o-mini both have context windows of 128k tokens (which corresponds to ~96k words) for reference, the wikipedia page for the United States has around 10k words alone and the agent will often need to visit more than 10 articles in one run of the game, not counting its own output, which eventually adds up to be significant. We'll solve this for now by resetting the messages of the agent every time it reaches a new wikipedia page, and providing an updated `user_message` (and possibly `system_message`) so that the agent can locate itself, and then proceed with the game. We'll address different methods for solving this issue later, you can probably already think of some. So be careful to include the current page and goal page for the agent in the `user_message`.\n",
                "\n",
                "</details>\n",
                "<br>\n",
                "\n",
                "\n",
                "<details><summary>Providing information to the agent</summary>\n",
                "\n",
                "There shouldn't be much on Wikipedia that the agent is completely unfamiliar with (AI companies *will* have scraped wikipedia), but it may be easily confused with something else, or be an article that was added before the training cutoff, and models can't always accurately use things in their training data anyway if they only come up once or twice. So you should use the game's get_summary function to provide details of the goal page to the agent in its initial message.\n",
                "\n",
                "</details>\n",
                "<br>\n",
                "\n",
                "<details><summary> Getting output from the agent </summary>\n",
                "\n",
                "In this case we'll have a lot more moving pieces than the `arithmeticGame` agent. In that case we could just print output from the agent loop. In this case, we strongly recommend that you should print output as it comes up in the agent class. If there's some chance you might not want to see this output, you should use a flag to determine whether to print content or not.\n",
                "\n",
                "</details>\n",
                "\n",
                "When making calls to the wikipediaGame class, make use of Python's `getattr()` function ([explanation here](https://www.w3schools.com/python/ref_func_getattr.asp)).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 258,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiAgent(SimpleAgent):\n",
                "    def __init__(self, task: BaseWikiGame, model = \"gpt-4o-mini\", tools = wiki_game_tools, verbose = True):\n",
                "        super().__init__(model=model, tools=tools, task=task)\n",
                "        \n",
                "        self.history = [] \n",
                "        self.full_history = [] # All messages that have been sent in the chat history. We have to erase each time a new page is reached for context window reasons.\n",
                "        self.path_count = 0\n",
                "        self.verbose = verbose\n",
                "\n",
                "    def verbose(self, verbose: bool):\n",
                "        self.verbose = verbose\n",
                "    \n",
                "    \n",
                "    def update_history(self, message):\n",
                "        \"\"\"\n",
                "        Update self.history and self.full_history with the message or list of messages.\n",
                "        \"\"\"\n",
                "        if isinstance(message, list):\n",
                "            self.history.extend(message)\n",
                "            self.full_history.extend(message)\n",
                "        else:\n",
                "            self.history.append(message)\n",
                "            self.full_history.append(message)\n",
                "        \n",
                "    def reset_history(self):\n",
                "        \"\"\"\n",
                "        Empty self.history of the agent.\n",
                "        \"\"\"\n",
                "        self.history = []\n",
                "\n",
                "    \n",
                "    def handle_tool_calls(self, response: ChatCompletionMessage):\n",
                "        \"\"\"\n",
                "        Handles tool_calls: \n",
                "            - Executes the tool calls using execute_tool_calls\n",
                "            - Appends the original tool call & tool_responses to the history\n",
                "            - If the agent has moved to a new page, resets the history\n",
                "            - If not, get the \"What's your next step?\" instruction from the task and append it to history\n",
                "        \"\"\"\n",
                "\n",
                "        # Append the original function calls to the conversation\n",
                "        self.update_history(response)\n",
                "\n",
                "        # Execute the tool calls\n",
                "        tool_responses = self.execute_tool_calls(response)\n",
                "\n",
                "        move_to_new_page = False\n",
                "        \n",
                "        # Handle tool responses\n",
                "        for tool_call, tool_response in zip(response.tool_calls, tool_responses):\n",
                "            self.update_history(apply_tool_call_format(tool_call, tool_response))\n",
                "            \n",
                "            if self.verbose: print(f\"\\nTOOL CALL: \\nTool = {tool_call.function.name}, Args = {tool_call.function.arguments} \\nTOOL RESPONSE:\\n {tool_response[:300]}\")\n",
                "\n",
                "            if tool_response.startswith(\"Moving page\"):\n",
                "                move_to_new_page = True\n",
                "        \n",
                "        if move_to_new_page:\n",
                "            # Reset the history\n",
                "            self.reset_history()\n",
                "            self.path_count += 1\n",
                "            print(f\"{(\"-\" * 50)} \\n\\nMOVED TO PAGE \\n\\nPATH HISTORY (N={self.path_count}): {\" -> \".join(self.task.page_history)} \\n\\n{(\"-\"*50)}\")\n",
                "\n",
                "            # Give starting instructions\n",
                "            self.start()\n",
                "\n",
                "        else:\n",
                "            # Append \"What's your next step?\" instruction\n",
                "            next_step_message = self.task.get_instructions(system=False, on_page=False, next_step=True)\n",
                "            self.update_history(next_step_message)\n",
                "            if self.verbose: print(f\"\\nUSER: \\n{next_step_message[0][\"content\"]}\")\n",
                "\n",
                "    def handle_refusal(self, response: ChatCompletionMessage):\n",
                "        self.update_history(apply_assistant_format(response.refusal))\n",
                "        if self.verbose: print(f\"\\nMODEL REFUSAL: {response.refusal}\")\n",
                "\n",
                "    def start(self):\n",
                "        \"\"\"\n",
                "        Gives the starting instructions to the agent when starting the game.\n",
                "        \"\"\"\n",
                "        instruction_message = self.task.get_instructions(system=True, on_page=True, next_step= False)\n",
                "        self.update_history(instruction_message)\n",
                "        if self.verbose: print(f\"\\nSYSTEM: \\n{instruction_message[0]['content']} \\n\\nUSER: \\n{instruction_message[1]['content']}\")\n",
                "\n",
                "    def run(self):\n",
                "        # Get the response from the model\n",
                "        response = self.get_response()\n",
                "\n",
                "        ## If response contains normal text, append this as an assistant response\n",
                "        if response.content is not None:\n",
                "            self.update_history(apply_assistant_format(response.content))\n",
                "            if self.verbose: print(f\"\\nMODEL RESPONSE: \\n{response.content}\")\n",
                "\n",
                "        # Handle the response\n",
                "        ## If tool calls, do the tool calls and return the response\n",
                "        if response.tool_calls:\n",
                "            self.handle_tool_calls(response)\n",
                "            \n",
                "        ## If no tool call: Handle edge cases\n",
                "        ### Check if there's a refusal to answer:\n",
                "        elif response.refusal:\n",
                "            self.handle_refusal(response)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Run the task\n",
                "```c\n",
                "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
                "\n",
                "You should spend up to 5 mins on this exercise.\n",
                "```\n",
                "\n",
                "Just like we did for the arithmetic agent, you should write an agent loop for the wikipedia agent (in this case you won't need to print output, as we handled it in the agent class so this function should be a very simple loop)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 256,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_loop(agent, game, num_loops = 10):\n",
                "\n",
                "    agent.start()\n",
                "\n",
                "    for i in range(num_loops):\n",
                "        if game.check_win():\n",
                "            print(\"Success!\")\n",
                "            return \n",
                "        agent.run()\n",
                "\n",
                "game = BaseWikiGame(\"1511 Dal√©ra\", \"Zal√≠ben√°\")\n",
                "agent = WikiAgent(task=game, model=\"gpt-4o-mini\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 257,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent_loop(agent, game, 10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4Ô∏è‚É£ Elicitation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You may have observed that while the above implementation of `WikiAgent` succeeds at Obama -> India, it fails at ... However, this doesn't mean that GPT4o-mini does not have this capability, but this might be blocked because we:\n",
                "\n",
                "- Prompted the model poorly\n",
                "\n",
                "- Stored the history poorly.\n",
                "\n",
                "- Didn't give the model sufficient tools to accomplish the task.\n",
                "\n",
                "- ...\n",
                "\n",
                "In general, it is hard to show that the model does not have a capability, even if we failed to demonstrate this capability. For example, it took *3.5 years* after the release of GPT-2 (and 2.5 years after the release of GPT-3) for people to discover that [chain-of-thought reasoning](https://arxiv.org/abs/2201.11903) massively improves model performance. A failure mode for AI safety is that people discover similar breakthroughs that significantly increases model performance with minimal additional training, which is not accounted for in our safety evaluations. Thus, LLM agent evals aim to elicit the best capability we possibly can, until we feel we've managed to gain [**evidence of absence**](https://en.wikipedia.org/wiki/Evidence_of_absence), **not** just **absence of evidence**.\n",
                "\n",
                "\n",
                "Broadly speaking, there are two categories of elicitation, narrow elicitation and general elicitation:\n",
                "\n",
                "1. Narrow elicitation: methods that improve model performance on a particular task, or small class of tasks, but won't necessarily impact model performance in general across many tasks. \n",
                "    - E.g. Give the model access to the content of arbitrary wikipedia articles - This will improve performance on this task significantly, but wouldn't generalize to other tasks.\n",
                "\n",
                "2. General elicitation: methods that improve model performance on a wide array of possible tasks. \n",
                "    - E.g. Chain-of-thought prompting - This tends to improve model performance on a wide array of tasks. These sorts of elicitation methods are the ones we're most interested in, as if researchers find an improvement to models that is roughly as easy and effective as chain-of-thought prompting, then we would see a very rapid increase in risk from AI.\n",
                "\n",
                "\n",
                "We will try X :\n",
                "1. Prompt engineering\n",
                "2. ReAct\n",
                "3. Inflexion\n",
                "\n",
                "Then, you "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prompting\n",
                "\n",
                "You should already be aware that prompting can have a large impact on model performance. There are a large number of possible changes to prompts for this task. You should experiment first with more general elicitation methods such as getting the agent to think more deeply, and output plans in different ways. \n",
                "\n",
                "After this, you might try a wide array of narrow elicitation methods including:\n",
                "\n",
                "- Telling the agent how many pages it's visited.\n",
                "\n",
                "- Telling the agent if it's already visited the page it's on (and how many times).\n",
                "\n",
                "- Schedule different prompts and planning methods for the \"zoom out\" and \"zoom in\" sections of the game, since the general strategy for the wikipedia game looks like:\n",
                "\n",
                "    Specific article (with few links) -> General article (with many links) -> Specific article (with few links)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Engineer prompts\n",
                "```c\n",
                "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµüîµ‚ö™‚ö™\n",
                "\n",
                "You should spend up to 20-25 mins on this exercise.\n",
                "```\n",
                "This exercise should be scoped as solving a specific problem;achieving a specific observable thing. Otherwise, it's hard to tell when \"you are done\" with changing the prompt.\n",
                "=============\n",
                "\n",
                "Remember that your prompts obviously will have to be robust to: \n",
                "\n",
                "* Different tasks within the wikipedia game, \n",
                "\n",
                "* Different states within those tasks,\n",
                "\n",
                "* Different failure-modes the agent could encounter.\n",
                "\n",
                "Mess around with the prompting setup and see if you can significantly improve performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGame(BaseWikiGame):\n",
                "\n",
                "    @property\n",
                "    def start_instruction(self):\n",
                "        return {\n",
                "            \"role\" : \"system\", \n",
                "            \"content\" : f\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}.\"\n",
                "            }\n",
                "            \n",
                "    @property\n",
                "    def on_page_instruction(self):\n",
                "        return {\n",
                "            \"role\" : \"user\",\n",
                "            \"content\" : f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary: \n",
                "            \n",
                "            [Begin Summary]\n",
                "            {self.get_page_summary(self.goal_page)}\n",
                "            [End Summary]\n",
                "            \"\"\"\n",
                "            }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 225,
            "metadata": {},
            "outputs": [],
            "source": [
                "game = WikiGame(\"Aristotle\", \"Othello\")\n",
                "agent = WikiAgent(game, model=\"gpt-4o-mini\")\n",
                "agent_loop(agent, game, 5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement the ReAct framework\n",
                "```c\n",
                "Difficulty: üî¥üî¥‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµüîµ‚ö™‚ö™\n",
                "\n",
                "You should spend up to 10-15 mins on this exercise.\n",
                "```\n",
                "\n",
                "Chain-of-thought prompting confers significant benefits to model performance, and you probably tried it when you messed around with prompting above. But when we're using LLMs as agents, we may want to provide a different structure to elicit reasoning. This is called the [**ReAct** framework](https://arxiv.org/abs/2210.03629); it consists of:\n",
                "\n",
                "- Getting the model to generate **Re**asoning about its current situation, and what sort of actions it should consider taking.\n",
                "\n",
                "- Then getting the model to perform an **Act**ion based on its outputted reasoning.\n",
                "\n",
                "Remember that if you're calling the model without tools, it won't have a description of the tools in its system message, so we'll have to ensure that the tool descriptions are in the `system_message` (this will lead to some redundancy when the model takes an action, but that's alright)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 226,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGameReAct(WikiGame):\n",
                "    def __init__(self, starting_page: str, goal_page: str, rules: Optional[List[Dict[str, str]]] = None, tools = None):\n",
                "        super().__init__(starting_page, goal_page, rules)\n",
                "        self.tool_descriptions = tools\n",
                "    \n",
                "    def add_tool(self, tools: dict | List[dict]):\n",
                "        if isinstance(tools, dict):\n",
                "            self.tool_descriptions.append(tools)\n",
                "        elif isinstance(tools, list):\n",
                "            self.tool_descriptions.extend(tool)\n",
                "\n",
                "    @property\n",
                "    def start_instruction(self):\n",
                "        # Provided a description of the tools in the system message. When generate is called with tools this is redundant, but when generate is called without tools, this is useful.\n",
                "        return {\n",
                "            \"role\" : \"system\",\n",
                "            \"content\" : f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tool_descriptions))} tools:\\n{\"\\n\".join([tool[\"function\"][\"name\"] + \": \" + tool[\"function\"][\"description\"] for tool in self.tool_descriptions])}\"\"\"\n",
                "        } \n",
                "    \n",
                "    @property\n",
                "    def apply_user_format(self):\n",
                "        # You may or may not want to edit your standard user message\n",
                "        return {\n",
                "            \"role\" : \"user\",\n",
                "            \"content\" : f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary: \n",
                "            \n",
                "            [Begin Summary]\n",
                "            {self.get_page_summary(self.goal_page)}\n",
                "            [End Summary]\n",
                "            \"\"\"\n",
                "        }\n",
                "    \n",
                "class WikiReActAgent(WikiAgent):\n",
                "\n",
                "    def generate_reason(self) -> ChatCompletionMessage:\n",
                "        # Get the model to reason about the current state of the game and add the response to the messages (you may not want to give it tools for this)\n",
                "        self.history.append(apply_user_format(\"Think carefully about your current situation and what actions you want to take to get closer to\" + self.task.goal_page.title + \".\"))\n",
                "        response = self.get_response(use_tool=False)\n",
                "        return response\n",
                "        \n",
                "    def generate_action(self) -> ChatCompletionMessage:\n",
                "        # Get the model to generate an action based on the reasoning and add the response to the messages\n",
                "        self.history.append(apply_user_format(\"What action do you want to take?\"))\n",
                "        response = self.get_response()\n",
                "        return response\n",
                "    \n",
                "    def generate_reason_and_action(self):\n",
                "        \"\"\"\n",
                "        Generate a reason, store this in history, then generate and return an action.\n",
                "        \"\"\" \n",
                "        reason = self.generate_reason()\n",
                "        self.update_history(apply_assistant_format(reason.content))\n",
                "        print(\"\\nModel response ('Reason'):\", reason.content)\n",
                "\n",
                "        action = self.generate_action()\n",
                "\n",
                "        return action\n",
                "\n",
                "    def run(self):\n",
                "        \"\"\"\n",
                "        Run one loop of the agent.\n",
                "        \"\"\"\n",
                "        response = self.generate_reason_and_action()\n",
                "\n",
                "        if response.tool_calls:\n",
                "            self.handle_tool_calls(response)\n",
                "        elif response.refusal:\n",
                "            self.handle_refusal(response)\n",
                "        \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You may have to rewrite your `agent_loop`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 200,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_loop_ReAct(game, agent, num_loops = 10):\n",
                "    agent.start()\n",
                "    for i in range(num_loops):\n",
                "        if game.check_win():\n",
                "            print(\"Success\")\n",
                "            return\n",
                "        agent.run()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 228,
            "metadata": {},
            "outputs": [],
            "source": [
                "game = WikiGameReAct(\"Aristotle\", \"Othello\", tools=wiki_game_tools)\n",
                "agent = WikiReActAgent(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "agent_loop_ReAct(game, agent)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Give the agent a history of visited pages\n",
                "```c\n",
                "Difficulty: üî¥‚ö™‚ö™‚ö™‚ö™\n",
                "Importance: üîµüîµ‚ö™‚ö™‚ö™\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "this should include writing a function that updates self.history different, otherwise should be merged with prompting.\n",
                "\n",
                "=====================\n",
                "\n",
                "You may notice that the agent frequently gets stuck in loops. Since we're already storing a history of page titles in the game class, we should try providing this information to the agent and see if it improves the looping behavior. Implement this below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGameHistory(WikiGameReAct):\n",
                "    \n",
                "    @property\n",
                "    def on_page_instruction(self):\n",
                "        return {\n",
                "            \"role\" : \"user\",\n",
                "            \"content\" : f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary: \n",
                "            \n",
                "            [Begin Summary]\n",
                "            {self.get_page_summary(self.goal_page)}\n",
                "            [End Summary]\n",
                "            \n",
                "            The pages you've visited so far has been: {\" -> \".join(self.page_history)}\"\"\"\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement a reflexion tool\n",
                "```c\n",
                "Difficulty: üî¥üî¥üî¥‚ö™‚ö™\n",
                "Importance: üîµüîµüîµ‚ö™‚ö™\n",
                "\n",
                "You should spend up to 10-15 mins on this exercise.\n",
                "```\n",
                "Inflexion should be better explained, with a diagram, not just in 1 sentence.\n",
                "\n",
                "=====================\n",
                "\n",
                "\n",
                "[This paper](https://arxiv.org/abs/2303.11366) finds better performance by LLMs on tasks when they can perform \"lookahead\" and get feedback on their plans. We will imitate this by allowing the agent to suggest candidate paths, and informing it where these paths go wrong (if they do). You'll need to add this tool to the list of tools.\n",
                "\n",
                "We don't want to provide the agent the links/content of every page when it does this lookahead, as then we'd just be reimplementing a smaller version of the game *inside the game*. Instead, we'll let the agent suggest paths without seeing any content or links, and then let it know if this path works. It's very likely that a suggested link will, at some point, not be accessible from one of the pages, but this should still help to guide the agent's plans."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WikiGameTestPath(WikiGame):\n",
                "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
                "        super().__init__(starting_page, goal_page, rules)\n",
                "\n",
                "        \n",
                "    def test_path(self, path: str) -> str:\n",
                "    \"\"\"\n",
                "    Test if a given path is valid.\n",
                "\n",
                "    Args:\n",
                "    path (str): A string representing a path, e.g., \"Barack Obama -> Indonesia -> India\"\n",
                "\n",
                "    Returns:\n",
                "    str: A message indicating whether the path is valid or where it fails.\n",
                "    \"\"\"\n",
                "    path_nodes = [node.strip() for node in path.split(\"->\")]\n",
                "    \n",
                "    if not path_nodes:\n",
                "        return \"ERROR: Empty path provided.\"\n",
                "    \n",
                "    if path_nodes[0] != self.current_page.title:\n",
                "        return f\"ERROR: The path should start with the current page: {self.current_page.title}\"\n",
                "    \n",
                "    for i in range(len(path_nodes) - 1):\n",
                "        current_node = path_nodes[i]\n",
                "        next_node = path_nodes[i + 1]\n",
                "        \n",
                "        permitted_links = set(link.lower() for link in self.get_permitted_links(current_node))\n",
                "        \n",
                "        if next_node.lower() not in permitted_links:\n",
                "            return f\"This path works until {next_node}, which is not accessible from {current_node}\"\n",
                "    \n",
                "    return \"This path is valid.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now write a description of this tool and add it to the list of `wiki_game_tools`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_path_tool = {\n",
                "    \"type\" : \"function\",\n",
                "    \"function\" : {\n",
                "        \"name\" : \"test_path\",\n",
                "        \"description\" : \"Accepts a test path string in the form \\\"current_page -> page1 -> page2 -> ... -> pageN\\\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \\\"success.\\\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\",\n",
                "        \"parameters\" : {\n",
                "            \"type\" : \"object\",\n",
                "            \"properties\": {\n",
                "                \"path\" : {\n",
                "                    \"type\" : \"string\",\n",
                "                    \"description\" : \"The path you want to test, formatted as \\\" current_page -> page1 -> page2 -> ... -> pageN\\\".\"\n",
                "                },\n",
                "            },\n",
                "            \"required\" : [\"path\"]\n",
                "        }\n",
                "    }\n",
                "}\n",
                "\n",
                "wiki_game_tools = [get_content_tool, move_page_tool, test_path_tool]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "game = WikipediaGameTestPath(\"William Pitt the Younger\", \"Central Vietnam\")\n",
                "agent = WikiAgentHistory(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n",
                "agent_loop_ReAct(game,agent, 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tool use"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This should be put into \"Bonus\" section, where people just play around, and we give some bullet suggestions of things to try.\n",
                "\n",
                "==============\n",
                "\n",
                "We can also give the agent additional tools that may be useful for the wikipediaGame task, or more general tooling methods. \n",
                "\n",
                "\n",
                "\n",
                "**[JAMES COMMENT]** I still need to figure out what to say about tool use. If you have any ideas then open to suggestions :) Lilian Weng did a little \"humans use tools\" and so do some animals thing. A cute animal pic might actually go over quite well here IMO.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                " but if you give the agent too many tools (especially with poor descriptions), then performance can often suffer. This happens most prominently when using more than 5-10 tools."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement a page summary tool\n",
                "```c\n",
                "Difficulty:üî¥üî¥‚ö™‚ö™‚ö™\n",
                "Importance:üîµüîµ‚ö™‚ö™‚ö™\n",
                "\n",
                "You should spend up to 10-15 mins on this exercise.\n",
                "```\n",
                "\n",
                "Implement a tool that allows an agent to get a summary of an accessible page. This imitates wikipedia's native 'hover summary' tool.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_page_summary = {\n",
                "    \"type\" : \"function\",\n",
                "    \"function\" : {\n",
                "        \"name\" : \"get_page_summary\",\n",
                "        \"description\" : \"Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags\",\n",
                "        \"parameters\" : {\n",
                "            \"type\" : \"object\",\n",
                "            \"properties\" : {\n",
                "                \"page\" : {\n",
                "                    \"type\" : \"object\",\n",
                "                    \"description\" : \"The wikipedia page you want to get the summary of.\"\n",
                "                }\n",
                "            },\n",
                "            \"required\" : [\"page\"]\n",
                "        }\n",
                "    }\n",
                "}\n",
                "\n",
                "class WikipediaGamePageSummary(WikipediaGameTestPath):\n",
                "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
                "        super().__init__(starting_page, goal_page, rules)\n",
                "\n",
                "        \n",
                "    def get_page_summary(self, page : WikipediaPage) -> str:\n",
                "        if is_permitted_link(self, page):\n",
                "            summary = page.content[0:500]\n",
                "            return summary[0: summary.rindex(\".\")+1]\n",
                "        else:\n",
                "            return \"This page is not accessible from the current page, so a summary cannot be returned.\"\n",
                "\n",
                "wiki_game_tools.append(get_page_summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement an arbitrary page summary/content tool\n",
                "```c\n",
                "Difficulty:üî¥‚ö™‚ö™‚ö™‚ö™\n",
                "Importance:üîµüîµ‚ö™‚ö™‚ö™\n",
                "\n",
                "You should spend up to 5-10 mins on this exercise.\n",
                "```\n",
                "\n",
                "Now implement a tool that allows the agent to suggest any wikipedia page, and get a brief summary of it. This may be helpful for the agent to formulate plans into the future.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_page_content = {\n",
                "    \"type\" : \"function\",\n",
                "    \"function\" : {\n",
                "        \"name\" : \"get_page_content\",\n",
                "        \"description\" : \"Get the content of a wikipedia page you are considering moving to. Anything which corresponds to a link you can select will be wrapped in <link></link> tags.\",\n",
                "        \"parameters\" : {\n",
                "            \"type\" : \"object\",\n",
                "            \"properties\" : {\n",
                "                \"page\" : {\n",
                "                    \"type\" : \"object\",\n",
                "                    \"description\" : \"The wikipedia page you want to get the content of.\"\n",
                "                }\n",
                "            },\n",
                "            \"required\" : [\"page\"]\n",
                "        }\n",
                "    }\n",
                "}\n",
                "\n",
                "class WikipediaGamePageContent(WikipediaGamePageSummary):\n",
                "    def __init__(self, starting_page : str, goal_page : str, rules : list | type[None] = None):\n",
                "        super().__init__(starting_page, goal_page, rules)\n",
                "    def get_page_content(self, arguments : dict) -> str:\n",
                "        page = arguments[\"page\"]\n",
                "        content = page.content\n",
                "        return content"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement a ctrl-F tool\n",
                "\n",
                "Still need to do this. Probably will though. Not super urgent. Might add more elicitation stuff later if I think of any that seem cool"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Supervised Fine-Tuning\n",
                "\n",
                "We're not going to conduct supervised fine-tuning here. But it's worth mentioning as an elicitation method, just because it can be so powerful. [ADD MORE INFO HERE LATER]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5Ô∏è‚É£ Bonus"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Implement additional rules"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test agent performance on these tasks:\n",
                "- Task 1\n",
                "\n",
                "- Task 2\n",
                "\n",
                "- Task 3\n",
                "\n",
                "- Task 4\n",
                "\n",
                "- Task 5\n",
                "\n",
                "- Task 6\n",
                "\n",
                "- Task 7\n",
                "\n",
                "- Task 8\n",
                "\n",
                "- Task 9\n",
                "\n",
                "- Task 10\n",
                "\n",
                "See what combination of tools appears to work best."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise - Rearrange so that each page is broken up by sections"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = get_page(\"Aristotle\")\n",
                "print(dir(x))\n",
                "print(x.section(\"Metaphysics/Substance\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "arena",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
