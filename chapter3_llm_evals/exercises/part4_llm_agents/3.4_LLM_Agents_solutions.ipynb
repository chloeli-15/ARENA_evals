{"cells": [{"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# [3.4] - LLM Agents (solutions)\n", "\n", "> **ARENA [Streamlit Page](https://arena-chapter3-llm-evals.streamlit.app/04_[3.4]_LLM_Agents)**\n", ">\n", "> **Colab: [exercises](https://colab.research.google.com/github/chloeli-15/ARENA_evals/blob/main/chapter3_llm_evals/exercises/part4_llm_agents/3.4_LLM_Agents_exercises.ipynb?t=20241209) | [solutions](https://colab.research.google.com/github/chloeli-15/ARENA_evals/blob/main/chapter3_llm_evals/exercises/part4_llm_agents/3.4_LLM_Agents_solutions.ipynb?t=20241209)**\n", "\n", "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-2noug8mpy-TRYbCnc3pzj7ITNrZIjKww), and ask any questions on the dedicated channels for this chapter of material.\n", "\n", "You can collapse each section so only the headers are visible, by clicking the arrow symbol on the left hand side of the markdown header cells.\n", "\n", "Links to all other chapters: [(0) Fundamentals](https://arena-chapter0-fundamentals.streamlit.app/), [(1) Transformer Interpretability](https://arena-chapter1-transformer-interp.streamlit.app/), [(2) RL](https://arena-chapter2-rl.streamlit.app/)."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["<img src = \"https://raw.githubusercontent.com/info-arena/ARENA_img/refs/heads/main/img/ch3-evals-cover.jpeg\" width = \"600\">"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Introduction"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Over the next two days, we'll be working with LLM agents. These consist of a scaffolding programs interacting with an LLM API. We'll also build two tasks, a simple and a complex one, in order to see how LLM agents act.\n", "\n", "We'll begin by learning building a simple Arithmetic Task and Arithmetic Agent. This should teach you the basics of function calling via the OpenAI API (Anthropic's API has minor differences, but operates in essentially the same way). Then, once we're comfortable with function calling and the general setup of LLM agents and tasks, we'll move on to building a more complex agent that plays the [Wikipedia Game](https://en.wikipedia.org/wiki/Wikipedia:Wiki_Game).\n", "\n", "Then we'll explore a variety of elicitation methods. These are methods for getting the best capabilities out of models, and is crucial for evaluating LLM agents. Elicitation tries to answer the question \"Can the model do this?\" Unfortunately, we'll almost never be able to prove that the model doesn't have a capability, and will only be able to say that with some effort, we couldn't get the model show this capability. This means we'll have to put a lot of effort into trying to exhibit the behavior in models (to have the highest confidence when we make a claim that the model can't exhibit this behavior). This will involve:\n", "\n", "* Improving our prompting\n", "* Improving our tools\n", "* Improving the way the histories are stored\n", "* Ensuring the model can access good information.*\n", "Each exercise will have a difficulty and importance rating out of 5, as well as an estimated maximum time you should spend on these exercises and sometimes a short annotation. You should interpret the ratings & time estimates relatively (e.g. if you find yourself spending about 50% longer on the exercises than the time estimates, adjust accordingly). Please do skip exercises / look at solutions if you don't feel like they're important enough to be worth doing, and you'd rather get to the good stuff!"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Content & Learning Objectives\n", "\n", "### 1\ufe0f\u20e3 Intro to LLM Agents\n", "> ##### Learning Objectives\n", "> - Understand why we want to evaluate LLM agents.\n", "> - Read resources about LLM agent evaluations to understand the current state of the field.\n", "> - Understand the common failure modes of LLM agents.\n", "\n", "### 2\ufe0f\u20e3 Building a Simple Arithmetic Agent\n", "> ##### Learning Objectives\n", "> - Understand that a LLM agent is just a \"glorified for-loop\" (of the scaffolding program interacting with the LLM API).\n", "> - Learn how to use function calling to allow LLMs to use external tools.\n", "> - Understand the main functionalities of an LLM agent.\n", "\n", "### 3\ufe0f\u20e3 Building a more Complex Agent: WikiGame\n", "> ##### Learning Objectives\n", "> - Get comfortable building a more complex task\n", "> - Understand how to build a more complex agent\n", "> - Observe the failure modes of a more complex agent\n", "\n", "### 4\ufe0f\u20e3 Elicitation\n", "> ##### Learning Objectives\n", "> - Understand the importance of elicitation in evaluating LLM agents\n", "> - Understand the different methods of elicitation\n", "> - Understand how to improve prompting, tools, history storage, and information access in LLM agents\n", "\n", "### 5\ufe0f\u20e3 Bonus\n", "> ##### Learning Objectives\n", ">\n", "> - Implement additional tools for elicitation\n", "> - Explore some of your own ideas for elicitation\n", "> - Explore some of the current research in elicitation"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import sys\n", "from importlib.metadata import distributions\n", "from pathlib import Path\n", "import warnings\n", "IN_COLAB = \"google.colab\" in sys.modules\n", "\n", "chapter = \"chapter3_llm_evals\"\n", "repo = \"ARENA_evals\"\n", "branch = \"main\"\n", "\n", "# Install dependencies\n", "if \"inspect_ai\" not in [dist.metadata[\"Name\"] for dist in distributions()]:\n", "    %pip install openai==1.56.1 anthropic inspect_ai tabulate wikipedia jaxtyping\n", "\n", "# Get root directory, handling 3 different cases: (1) Colab, (2) notebook not in ARENA repo, (3) notebook in ARENA repo\n", "root = (\n", "    \"/content\"\n", "    if IN_COLAB\n", "    else \"/root\"\n", "    if repo not in os.getcwd()\n", "    else str(next(p for p in Path.cwd().parents if p.name == repo))\n", ")\n", "\n", "if Path(root).exists() and not Path(f\"{root}/{chapter}\").exists():\n", "    if not IN_COLAB:\n", "        !sudo apt-get install unzip\n", "        %pip install jupyter ipython --upgrade\n", "\n", "    if not os.path.exists(f\"{root}/{chapter}\"):\n", "        !wget -P {root} https://github.com/chloeli-15/ARENA_evals/archive/refs/heads/{branch}.zip\n", "        !unzip {root}/{branch}.zip '{repo}-{branch}/{chapter}/exercises/*' -d {root}\n", "        !mv {root}/{repo}-{branch}/{chapter} {root}/{chapter}\n", "        !rm {root}/{branch}.zip\n", "        !rmdir {root}/{repo}-{branch}\n", "\n", "if IN_COLAB:\n", "    from google.colab import userdata\n", "    try:\n", "        os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n", "    except:\n", "        warnings.warn(\"You don't have an OPENAI_API_KEY variable set in the secrets tab of your google colab.\")\n", "\n", "\n", "if f\"{root}/{chapter}/exercises\" not in sys.path:\n", "    sys.path.append(f\"{root}/{chapter}/exercises\")\n", "\n", "os.chdir(f\"{root}/{chapter}/exercises\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "import os\n", "import sys\n", "from pathlib import Path\n", "\n", "import wikipedia\n", "from wikipedia import WikipediaPage\n", "from wikipedia import DisambiguationError, PageError\n", "from openai import OpenAI\n", "from openai.types.chat.chat_completion_message_tool_call import (\n", "    ChatCompletionMessageToolCall,\n", ")\n", "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n", "from anthropic import Anthropic\n", "from typing import Literal, Optional, Dict, List, Any\n", "from abc import abstractmethod\n", "import math\n", "import re\n", "import openai\n", "\n", "\n", "#Make sure exercises are in the path\n", "chapter = r\"chapter3_llm_evals\"\n", "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n", "section_dir = (exercises_dir / \"part4_llm_agents\").resolve()\n", "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n", "os.chdir(exercises_dir)\n", "\n", "from utils import import_json, save_json, retry_with_exponential_backoff, pretty_print_questions, load_jsonl, omit\n", "from utils import countrylist\n", "from utils import evaluate_expression, apply_user_format, apply_assistant_format, establish_client_anthropic, establish_client_OpenAI, retry_with_exponential_backoff\n", "import part4_llm_agents.tests as tests\n", "\n", "MAIN = __name__ == \"__main__\"\n", "\n", "\n", "api_key = os.getenv(\"OPENAI_API_KEY\")\n", "openai.api_key = api_key\n", "\n", "client = OpenAI()"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1\ufe0f\u20e3 Intro to LLM Agents\n", "\n", "> ##### Learning Objectives\n", ">\n", "> - Read resources about LLM agent evaluations to understand the current state of the field.\n", "> - Understand the common failure modes of LLM agents."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## What is an LLM agent?\n", "\n", "An LLM agent consists of a scaffolding program interacting with an LLM API. This typically involves a loop of the following steps:\n", "\n", "1. The scaffolding program sends instructions to the LLM, typically containing information on the task goal, the actions available to the LLM, and relevant task information.\n", "2. The LLM processes the input and outputs an action in text (e.g. \"calls\" the calculate() tool in text).\n", "3. The scaffolding program executes the action and returns the outcome (e.g. it runs the calculate() function in the background and returns the output to the agent).\n", "4. The LLM observes the results and decides the next action.\n", "5. Repeating the cycle until the task is complete\n", "\n", "The two basic components of scaffolding are:\n", "\n", "* Tool calling: This allows LLMs to use tools by providing a text description of the tool. The LLM can choose to use this tool by \"calling\" it in its text output. If it uses a tool, the scaffolding will execute this tool on the LLM's behalf (e.g. by running a python function, sending request to an external API etc.) and return the result of this tool call to the agent.\n", "* Prompting: This describes the task state to the LLM, assists it in its tool use, or instruct it to use chain-of-thought to give the LLM more \"thinking time\" etc."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/refs/heads/main/img/ch3-llm-agent.png\" width=\"800\">\n", "\n", "Diagram based on METR's [*Evaluating Language-Model Agents on Realistic Autonomous Tasks*], Figure 2."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Why evaluate LLM agents?\n", "\n", "There are at least two reasons for why we might want to evaluate LLM agents.\n", "\n", "1. **Measuring the maximum capabilities of a model**\n", "\n", "For estimating safety risks, we want to measure the **ceiling** of dangerous capabilities. LLMs on their own often fail in easy-to-fix ways, as you will see. For example:\n", "\n", "- They often claim to be incapable of tasks that they can actually perform.\n", "- They can easily get stuck in loops.\n", "- They can give up and ask the user for help\n", "- They can hallucinate facts, or even misunderstand their own prior reasoning and hallucinate a faulty conclusion.\n", "- They can be limited by primitive tools.\n", "- They can be overly or underly sensitive to information in their prompts.\n", "- They can have bugs.\n", "\n", "This means that when a model fails to accomplish a task, it may still have the raw capability to succeed, but just require simple fixes that will unlock this capability. We want to eliminate the possibility of large capability improvements from relatively little effort, because this means our evals would have underestimated the true capability and risks associated with a model. Therefore, we want to try hard to elicit their raw capabilities via scaffolding, so that we can evaluate LLMs at their *best*.\n", "\n", "\n", "2. **Measuring the alignment of LLMs in agentic scenarios**\n", "\n", "We do not know if our current alignment techniques (e.g. supervised fine-tuning, RLHF) for aligning LLM chatbots will still work when LLMs are acting as agents in more complex scenarios. It is possible that these methods will not generalize well to agentic scenarios, and we want to test this.\n", "\n", "We know today that LLMs are being used as more than just chatbots. Since the release of ChatGPT, the use of LLMs as agentic systems has grown signifcantly. These agents started off rather disappointingly initially, when they were based on GPT-3.5. However as more powerful LLMs come out and AI companies ensure their LLMs are better at tool-use, these agents are improving rapidly.\n", "\n", "<details><summary>Further resources on LLM agent evaluations</summary>\n", "\n", "- [Evaluating Language-Model Agents on Realistic Autonomous Tasks](https://evals.alignment.org/Evaluating_LMAs_Realistic_Tasks.pdf) (Kinniment et al., ARC Evaluations Team (now METR), 2023)\n", "- [Large Language Models can Strategically Deceive their Users when Put Under Pressure](https://arxiv.org/pdf/2311.07590) (Scheurer et al., Apollo Research, ICLR 2024)\n", "- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) (Lilian Weng, OpenAI Safety Team, 2023)\n", "- [AXRP Episode 34 - AI Evaluations with Beth Barnes](https://www.alignmentforum.org/posts/vACr4DExfeRMaCoo7/axrp-episode-34-ai-evaluations-with-beth-barnes) (Daniel Filan, 2024)\n", "-[Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/pdf/2303.11366) (Shinn et al., 2023)\n", "- [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://arxiv.org/pdf/2304.13007) (Yoran et al., 2024)\n", "- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761) (Schick et al., META AI Research, 2023)\n", "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n", "- [Anthropic Function Calling Guide](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)\n", "\n", "</details>"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2\ufe0f\u20e3 Building a Simple Arithmetic Agent\n", "\n", "> ##### Learning Objectives\n", ">\n", "> - Learn how to use function calling to allow LLMs to use external tools.\n", "> - Understand the main functionalities of an LLM agent."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["In general, most LLM agents share these core components:\n", "\n", "<img src=\"https://raw.githubusercontent.com/chloeli-15/ARENA_img/refs/heads/main/img/ch3-sec4-agent-overview.png\" width=\"1000\">"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["1. **LLM API interface**: A basic function that makes API calls (e.g. `get_response()`). <!-- (IN AGENT)-->\n", "2. **Actions/Tools**: A set of actions the agent can take. <!-- (MOSTLY IN TASK)-->\n", "3. **Task State Management**: Keeping track of the current state of the task and any relevant context. <!-- (IN TASK MOSTLY)-->\n", "4. **Memory**: A way to store and retrieve information from past interactions (i.e. chat history). The simplest implemention is usually to store the list of past chat messages in a `chat_history` class attribute. <!-- (IN AGENT)-->\n", "5. **Observation Parser**: Functions to parse and interpret the results of actions and update the state. <!-- (IN TASK MOSTLY)-->\n", "6. **Decision/Execution Logic**: The rules or algorithms used to choose actions based on the current state and LLM output. <!-- (KIND OF IN BETWEEN)-->\n", "7. **Task-Specific Information**: Any additional information or functions specific to the task at hand. <!-- (IN TASK)-->\n", "\n", "These components are implemented across the `Task`, `Agent`, and `Tool` classes. However, the specific breakdown of these components in our implementation is a design choice and can vary depending on the task. While some seem more natural (e.g. LLM API interface goes into `Agent`, task state management goes into task), others can vary (e.g. Tools can be functions within the Task or the Agent, as opposed to being separate classes; observation parsing could go either way). In general, we want to maximize separability and minimize interfaces/dependencies, so that we can easily swap out the agent for the same task, or vice versa."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Task\n", "\n", "In an LLM agent eval, there will usually be a `Task` class that interacts with the `Agent`. In general, the `Task` will:\n", "\n", "- Prepare and provide the task instruction (and necessary files, functions etc) to the agent\n", "- Parse and score the agent's output\n", "- Update the task state accordingly (e.g. proceeds onto the next step of the task, ends the task)."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Build a simple arithmetic task\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> \n", "> You should spend up to 20-25 minutes on this exercise.\n", "> ```\n", "\n", "We will build a toy task called `ArithmeticTask`. This task takes in two numbers and create a list of arithmetic calculation problems with these two numbers, using arithmetic operations defined in `operations`. It should have methods to do the following:\n", "\n", "- Get the current problem (e.g. at the start this will be \"Calculate `num1` + `num2`\")\n", "- Check if a given answer is correct\n", "- Update the current problem if the model answer was correct, (or if the model refuses to answer the question).\n", "- Check if all problems have been solved\n", "\n", "**How to handle calculations?** We have implemented a helper function `evaluate_expression()` to evaluate the arithmetic expressions, which you should use in your implementation of `execute()`. `evaluate_expression()` takes an arithmetic expression as a string (e.g. \"3+5\") and returns the result as a string (e.g. \"8.0\").\n", "\n", "<details><summary>Aside: Why not use Python's in-built <code>eval()</code> function?</summary>\n", "\n", "Python's `eval()` function evaluates an arbitrary string expression, and so allows AI models to run arbitrary code. Unless you have set up a container or sandboxed environment, it is very bad to allow LLMs to run arbitrary code on your computer!\n", "\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ArithmeticTask:\n", "    def __init__(self, num1: int | float, num2: int | float):\n", "        self.num1 = num1\n", "        self.num2 = num2\n", "        self.operations: List[str] = [\"+\", \"-\", \"*\", \"/\", \"%\", \"//\"]\n", "        self.correct_answers: Dict[str, float] = self._generate_answers()\n", "        self.is_solved: Dict[str, bool] = {expr: False for expr in self.correct_answers}\n", "        self.current_task_number = 0\n", "\n", "    def _generate_answers(self) -> Dict[str, float]:\n", "        \"\"\"\n", "        Generates a dictionary the correct answers for all possible tasks\n", "\n", "        Returns:\n", "            Dict[str, float]: A dictionary with the expression as key and the correct answer as value\n", "        \"\"\"\n", "        return {\n", "            f\"{self.num1} {op} {self.num2}\": evaluate_expression(f\"{self.num1} {op} {self.num2}\")\n", "            for op in self.operations\n", "        }\n", "\n", "    @property\n", "    def get_current_task(self) -> str:\n", "        \"\"\"\n", "        Gets the current task for the agent\n", "\n", "        Returns:\n", "            str: A string containing the current task\n", "        \"\"\"\n", "        return f\"{str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}\"\n", "    @property\n", "    def instruction(self) -> dict:\n", "        \"\"\"\n", "        Gets a string containing instructions for the current task for the agent. (This will be fed to the agent as a user prompt)\n", "\n", "        Returns:\n", "            dict: A dictionary containing the instructions for the current task, formatted as a user prompt.\n", "        \"\"\"\n", "        return apply_user_format(f\"Calculate the result of the following expression: {str(self.num1)} {self.operations[self.current_task_number]} {str(self.num2)}. Give your final answer in the format: <answer>NUMBER</answer>, where NUMBER is a numerical value\")\n", "\n", "    def check_solved(self) -> bool:\n", "        \"\"\"\n", "        Checks if all tasks have been solved\n", "\n", "        Returns:\n", "            bool: True if all tasks have been solved, False otherwise\n", "        \"\"\"\n", "        return all(self.is_solved.values())\n", "\n", "    def check_answer(self, model_answer: str | float) -> bool:\n", "        \"\"\"\n", "        Checks if the model's answer is correct\n", "\n", "        Args:\n", "            model_answer (str): The model's answer\n", "\n", "        Returns:\n", "            bool: True if the model's answer is correct, False otherwise\n", "        \"\"\"\n", "        correct_answer = self.correct_answers[self.get_current_task]\n", "        return math.isclose(\n", "            float(model_answer), correct_answer, rel_tol=1e-5, abs_tol=1e-8\n", "        )\n", "\n", "    def update_current_task(self):\n", "        \"\"\"\n", "        Sets is_solved for the current task to True and increments self.current_task_number by one\n", "        \"\"\"\n", "        self.is_solved[self.get_current_task] = True\n", "        self.current_task_number = (self.current_task_number + 1) % len(self.operations)\n", "\n", "tests.ArithmeticTaskTests(ArithmeticTask)\n", "\n", "x = ArithmeticTask(10, 15)\n", "for problem, answer in x.correct_answers.items():\n", "    print(f\"{problem} = {answer}\")"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Tool use via function calling\n", "\n", "The simplest way for LLMs to take actions is via function calling. **Function calling** is a built-in feature of LLM Chat APIs that allows models to use external \"tools\" (i.e. Python functions, APIs) by simply receiving and outputing text. This involves 5 simple steps:\n", "\n", "1. Pick a function in your codebase that the model should be able to call\n", "2. Describe your function in the syntax of the model's API so the model knows how to call it\n", "3. Pass your function definitions as available \u201ctools\u201d to the model, along with the messages\n", "4. Receive and handle the model response\n", "5. Provide the function call result back to the model \n", "\n", "**This loop of prompting the LLM with tools, executing its actions, and returning the results forms the basis of all LLM agents.** It allows LLMs to perform complex tasks like playing a game or completing a coding project \"autonomously\".\n", "\n", "We will implement each step of the loop below."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Write `CalculateTool`\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\n", "> \n", "> You should spend up to 10-15 minutes on this exercise.\n", "> ```\n", "\n", "We will define a tool class for our simple `calculate()` function with the following structure (don't need to run the code cell below, just read):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Tool:\n", "    name: str # The name of the tool that models will use to call it\n", "\n", "    @staticmethod\n", "    def execute(task: Any, input: str) -> str: \n", "        \"\"\"Executes the tool and returns the result as a string\"\"\"\n", "        ...\n", "\n", "    @property\n", "    def description(self) -> dict: \n", "        \"\"\"Returns the tool description in the API syntax\"\"\"\n", "        ..."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["For the `CalculateTool`, you should implement the following methods:\n", "- `execute()` - This should take in an arithmetical expression as string (e.g. `\"3+5\"`) and return the result of this expression (also as a string). The `execute()` function should take the task as a variable, as often tools will need to be able to make changes to the task state (e.g. update the current problem).\n", "- `description` - This should return a dictionary containing the tool description in the correct API syntax. \n", "\n", "#### Tool Description\n", "\n", "Models like ChatGPT and Claude are fine-tuned to interpret and respond to `tool` descriptions appropriately, just like `user` and `system` messages. Below is an example of a typical tool description for the OpenAI API (see their [function calling guide](https://platform.openai.com/docs/guides/function-calling) for more details). Note that this may differ between APIs."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["```python\n", "{\n", "    \"type\": \"function\",\n", "    \"function\": {\n", "        {   \n", "        \"type\": \"function\",\n", "        \"function\":{\n", "            \"name\": \"get_delivery_date\",\n", "            \"description\": \"Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'\",\n", "            \"parameters\": {\n", "                \"type\": \"object\",\n", "                \"properties\": {\n", "                    \"order_id\": {\n", "                        \"type\": \"string\",\n", "                        \"description\": \"The customer's order ID.\",\n", "                        },\n", "                    },\n", "                \"required\": [\"order_id\"],\n", "                \"additionalProperties\": false,\n", "                },\n", "            },\n", "        },\n", "    },\n", "}\n", "```"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["<details><summary><b>Good practices for writing tool descriptions</b></summary>\n", "\n", "Here are some good practices for writing tool descriptions for Claude according to Anthropic, which should generalize to other chat models:\n", "- Provide extremely detailed descriptions. This is by far the most important factor in tool performance. Your descriptions should explain every aspect of the tool, including:\n", "    - What the tool does\n", "    - When it should be used (and when it shouldn\u2019t)\n", "    - What each parameter means and how it affects the tool\u2019s behavior\n", "    - Any important caveats or limitations, such as what information the tool does not return if the tool name is unclear. The more context you can give Claude about your tools, the better it will be at deciding when and how to use them. Aim for at least 3-4 sentences per tool description, more if the tool is complex.\n", "- Prioritize descriptions over examples. While you can include examples of how to use a tool in its description or in the accompanying prompt, this is less important than having a clear and comprehensive explanation of the tool\u2019s purpose and parameters. Only add examples after you\u2019ve fully fleshed out the description.\n", "\n", "Read Anthropic's examples of what good and bad tool calling looks like [here](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-of-a-good-tool-description). \n", "\n", "</details>\n", "\n", "Write your tool class for the `CalculateTool` below."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CalculateTool():\n", "    \"\"\"\n", "\n", "    A tool that calculates the result of an arithmetic expression input as a string and returns as a string.\n", "\n", "    Attributes:\n", "        name (str): The name of the tool\n", "\n", "    Methods:\n", "        - execute(task: Optional[], input: str) -> str: Executes the tool on the input and returns the result as a string.\n", "        - description() -> str: Returns a description of the tool.\n", "\n", "    \"\"\"\n", "    name = \"calculate\"\n", "\n", "    @staticmethod\n", "    def execute(expression: str, task: Optional[ArithmeticTask] = None) -> str:\n", "        \"\"\"\n", "        Evaluates the string expression in Python using `evaluate_expression()` and returns the result as a string\n", "\n", "        Args:\n", "            expression (str): The arithmetic expression to evaluate\n", "            task (ArithmeticTask | None): Not used in this function\n", "\n", "        Returns:\n", "            str: The result of the arithmetical expression as a string\n", "        \"\"\"\n", "        try:\n", "            return str(evaluate_expression(expression))\n", "        except (SyntaxError, NameError, ZeroDivisionError) as e:\n", "            return f\"Error: {str(e)}\"\n", "    @property\n", "    def description(self):\n", "        \"\"\"\n", "        Provides the description of the tool\n", "\n", "        Returns:\n", "            dict: The JSON description of the tool for the OpenAI API\n", "        \"\"\"\n", "        return {\n", "            \"type\": \"function\",\n", "            \"function\": {\n", "                \"name\": self.name,\n", "                \"description\": 'Calculates the result of an arithmetic expression. For example, you could provide an input in the form \"2+3\" and the function would return 5. Or you could provide an expression like \"10/3\" and the function would return 3.3333333333333335.',\n", "                \"parameters\": {\n", "                    \"type\": \"object\",\n", "                    \"properties\": {\n", "                        \"expression\": {\n", "                            \"type\": \"string\",\n", "                            \"description\": \"The arithmetic expression that you want to be evaluated.\",\n", "                        }\n", "                    },\n", "                    \"required\": [\"expression\"],\n", "                    \"additionalProperties\": False,\n", "                },\n", "            },\n", "        }\n", "\n", "tests.run_calculate_tool_tests(CalculateTool)\n", "\n", "Calculator = CalculateTool()"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["You can pass the tool to the model by providing the tool description to the `tools` parameter of the API call. This input has to be a list. The following code provides a standard example of this."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["messages = [{\"role\": \"user\", \"content\": \"Calculate 2+3\"}]\n", "client = OpenAI()\n", "\n", "response = client.chat.completions.create(\n", "    model=\"gpt-4o-mini\",\n", "    messages=messages,\n", "    tools=[Calculator.description],\n", "    tool_choice=\"auto\",\n", ")\n", "\n", "print(response.choices[0].message.content)\n", "print(response.choices[0].message.tool_calls)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["<details><summary>Why is <code>message.content = None</code>?</summary>\n", "\n", "When LLMs use tools, they often don't generate any text output. This can be a problem later when you try to get the model to do chain-of-thought reasoning. To get around this, it can be better to make two calls to the model for more complex tool use: one call to get the model to reason about the actions it should take, and then another to get the model to use a tool to take those actions.\n", "\n", "</details> \n", "\n", "<details><summary> Aside - What is <code>@staticmethod</code>?</summary>\n", "\n", "The `@staticmethod` decorator in Python defines a \"static method\" within a class, which has the following properties:\n", "1. They don't use instance- or class-specific data, thus does not require a first parameter `self` or `cls`.\n", "2. They're often used as utility functions related to the class.\n", "\n", "For example, if we defined a class of `MathOperations` as follows:\n", "\n", "```python\n", "class MathOperations:\n", "    @staticmethod\n", "    def add(x : int | float, y : int | float) -> int | float:\n", "        \"\"\"Evaluates the string expression and returns the result as a string.\"\"\"\n", "        return x + y\n", "```\n", "\n", "The `add()` method could be called on the class itself without creating an instance:\n", "\n", "   ```python\n", "   result = MathOperations.add(2, 3)\n", "   ```\n", "\n", "You can also call it on an instance of the class, but it doesn't utilize the instance in any way (it doesn't have access to `self`):\n", "   ```python\n", "   operation = MathOperations()\n", "   result = operation.add(2, 3)\n", "   ```\n", "\n", "Typically, you would make \"stand-alone\" functions that do not depend on class methods or class/instance attributes a static method. Using `@staticmethod` in this case helps with the following:\n", "1. Makes the code's intent clearer (this method doesn't need class or instance data).\n", "2. Slightly improves performance (no `self` argument needs to be passed).\n", "3. Allows the method to be used without creating an instance of the class.\n", "\n", "</details>"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Return tool call results\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\n", "> ```\n", "\n", "The model always gives its output as a `ChatCompletionMessage` object. If this contains a tool call, you will need to add **two** items to the `messages` list to return back to the model:\n", "1. The `ChatCompletionMessage` object itself, containing the original tool call message generated by the model. \n", "2. The **tool response** message, describing the results of the tool call in a specific [format](https://platform.openai.com/docs/guides/function-calling/step-4-receive-and-handle-the-model-response). Similar to the system and user message, the tool response message is a dictionary with `role`, `content`, and additionally `tool_call_id` and `name` keys. (Note: This is **not** the same as the tool description we wrote above). \n", "\n", "If we tried to generate the next response without returning these after the model's tool call, the API will raise an error.\n", "\n", "<details><summary>How to access the <code>ChatCompletionMessage</code> object</summary>\n", "\n", "The `chat.completions.create()` function returns a `response` with a complicated data structure. The `ChatCompletionMessage` is nested inside and can be accessed via `response.choices[0].message` (don't need to run the code below, just read).\n", "\n", "```python\n", "# This is an example of the `response.choices[0]` object. `ChatCompletionMessage` is in the `message` parameter.\n", "Choice(\n", "    finish_reason=\"tool_calls\",\n", "    index=0,\n", "    logprobs=None,\n", "    message=chat.completionsMessage(\n", "        content=None,\n", "        role=\"assistant\",\n", "        function_call=None,\n", "        tool_calls=[\n", "            chat.completionsMessageToolCall(\n", "                id=\"call_62136354\",\n", "                function=Function(arguments='{\"expression\":\"2+3\"}', name=\"calculate\"),\n", "                type=\"function\",\n", "            )\n", "        ],\n", "    ),\n", ")\n", "```\n", "</details>\n", "\n", "\n", "We have provided a function that formats the tool response correctly for the OpenAI API."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def apply_tool_call_format(\n", "    tool_call: ChatCompletionMessageToolCall, content: str\n", ") -> dict:\n", "    \"\"\"\n", "    Formats the response of a tool call to be returned to the model.\n", "    Args:\n", "        - tool_call (ChatCompletionMessageToolCall) : The tool call object\n", "        - content (str) : This is the tool response (i.e. results from executing the tool)\n", "\n", "    Returns:\n", "        - dict : The formatted tool response to be returned to the model\n", "    \"\"\"\n", "    return {\n", "        \"role\": \"tool\",\n", "        \"content\": content, # e.g. \"5\"\n", "        \"tool_call_id\": tool_call.id,\n", "        \"name\": tool_call.function.name\n", "    }"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Now use the function above to return a tool call response to the model after the following message:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["messages = [{\"role\": \"user\", \"content\": \"Calculate 5/3. Be precise.\"}]\n", "response = client.chat.completions.create(\n", "    model=\"gpt-4o-mini\",\n", "    messages=messages,\n", "    tools=[Calculator.description],\n", "    tool_choice=\"auto\",\n", ")\n", "messages.extend(\n", "    [\n", "        response.choices[0].message,\n", "        apply_tool_call_format(\n", "            response.choices[0].message.tool_calls[0],\n", "            Calculator.execute(\n", "                json.loads(\n", "                    response.choices[0].message.tool_calls[0].function.arguments\n", "                )[\"expression\"]\n", "            ),\n", "        ),\n", "    ]\n", ")\n", "\n", "response_to_tool_calls = client.chat.completions.create(\n", "    model=\"gpt-4o-mini\",\n", "    messages=messages,\n", "    tools=[Calculator.description],\n", "    tool_choice=\"auto\",\n", ")\n", "print(response_to_tool_calls.choices[0].message.content)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Agent\n", "\n", "We will first implement a `SimpleAgent` class that is not specific to the `ArithmeticTask`, so that we can see the key components of a generic LLM agent."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement `SimpleAgent`\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\n", "> \n", "> You should spend up to 20-25 minutes on this exercise.\n", "> ```\n", "\n", "Build out the following simple agent class by filling in `get_response()` and `execute_tool_calls()` functions.\n", "\n", "- `get_response()`: This should make an API call and return the `ChatCompletionMessage`from the model. It should be able to either use tool calling or not, depending on the `use_tool` argument).\n", "- `execute_tool_calls()`: This should execute the tool calls in the message and return a list of tool responses as strings (we can format them correctly in `run()`).\n", "- `run()`: This should define the main execution logic for running 1 loop of the agent. As this is largely determined by the task, this method in `SimpleAgent` is just a dummy method and should be overridden in specific agent classes."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SimpleAgent:\n", "    def __init__(\n", "        self,\n", "        task: Any = None,\n", "        model: Literal[\"gpt-4o-mini\"] = \"gpt-4o-mini\",\n", "        tools: Optional[List[Any]] = None,\n", "        chat_history: Optional[List[dict]] = None,\n", "    ):\n", "        self.model = model\n", "        self.task = task\n", "        self.tools = tools\n", "        self.client = OpenAI()\n", "        self.chat_history = chat_history if chat_history else []\n", "\n", "    @retry_with_exponential_backoff\n", "    def get_response(self, use_tool: bool = True) -> ChatCompletionMessage:\n", "        \"\"\"\n", "        Get the response from the model via an API call, with the option of tool calling.\n", "\n", "        Args:\n", "            use_tool (bool): Whether to use tool calling or not\n", "\n", "        Returns:\n", "            ChatCompletionMessage: The response from the model\n", "        \"\"\"\n", "        response = self.client.chat.completions.create(\n", "            model=self.model,\n", "            messages=self.chat_history,\n", "            tools=[tool.description for tool in self.tools] if use_tool else None,\n", "            tool_choice=\"auto\" if use_tool else None,\n", "        )\n", "        return response.choices[0].message\n", "    def execute_tool_calls(self, message: ChatCompletionMessage) -> List[str]:\n", "        \"\"\"\n", "        Execute the tool calls in the message and return a list of tool_responses.\n", "\n", "        Args:\n", "            message (ChatCompletionMessage): The message containing the tool calls\n", "\n", "        Returns:\n", "            List[str]: A list of tool responses (as strings)\n", "        \"\"\"\n", "        tool_calls = message.tool_calls\n", "\n", "        tool_responses = []\n", "        for tool_call in tool_calls:\n", "            if not self.task:\n", "                raise ValueError(\"Task is not set. Cannot execute tool calls.\")\n", "            func = next(\n", "                (tool for tool in self.tools if tool.name == tool_call.function.name),\n", "            )\n", "            arguments = json.loads(tool_call.function.arguments)\n", "            tool_response = func.execute(**arguments, task=self.task)\n", "            tool_responses.append(tool_response)\n", "\n", "        return tool_responses\n", "    def run(self, with_tool: bool = True) -> ChatCompletionMessage:\n", "        \"\"\"\n", "        Default implementation of run method.\n", "        This can be overridden in subclasses for specific behavior.\n", "\n", "        Args:\n", "            with_tool (bool): Whether to use tool calling or not\n", "\n", "        Returns:\n", "            str: The response from the model\n", "        \"\"\"\n", "        print(f\"Running SimpleAgent...\")\n", "        instruction = self.task.instruction\n", "        self.chat_history.append(instruction)\n", "        response = self.get_response(use_tool=with_tool)\n", "        return response\n", "\n", "tests.test_execute_tool_calls(SimpleAgent, CalculateTool, ArithmeticTask)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Then running the agent should cause the tool calls to be executed."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_simple_agent = SimpleAgent(task=ArithmeticTask(10, 15), tools=[Calculator])\n", "my_simple_agent.run()"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Build an `ArithmeticAgent`\n", "\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\n", "> \n", "> You should spend up to 20-25 minutes on this exercise.\n", "> ```\n", "\n", "Now build our agent that will interact with the `ArithmeticTask` (with a calculator tool). Fill in the methods in the class below."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ArithmeticAgent(SimpleAgent):\n", "    \"\"\"\n", "    ArithmeticAgent class for doing simple arithmetic tasks.\n", "\n", "    Inherits from SimpleAgent which includes the following attributes and methods:\n", "\n", "    Attributes:\n", "        model (str): The model used for generating responses (inherited)\n", "        tool_descriptions (List[dict]): List of tool descriptions (inherited)\n", "        client (OpenAI): OpenAI client for API calls (inherited)\n", "        task (ArithmeticTask): The current task being executed (inherited)\n", "        chat_history (List[dict]): History of interactions (inherited)\n", "\n", "    Methods:\n", "        get_response(use_tool: bool = True) -> ChatCompletionMessage:\n", "            Get response from the model (inherited)\n", "\n", "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]:\n", "            Execute tool calls from the model's response (inherited)\n", "\n", "        run(with_tool: bool = True) -> bool:\n", "            Run one loop of the Arithmetic agent\n", "    \"\"\"\n", "\n", "    def __init__(\n", "        self,\n", "        model: Literal[\"gpt-4o-mini\"] = \"gpt-4o-mini\",\n", "        task: ArithmeticTask = None,\n", "        tools: Optional[List[Any]] = None,\n", "        chat_history: List[dict] = None,\n", "        verbose: bool = True,\n", "    ):\n", "        super().__init__(model=model, task=task, tools=tools, chat_history=chat_history)\n", "        self.verbose = verbose\n", "\n", "    def handle_tool_calls(self, response: ChatCompletionMessage):\n", "        \"\"\"\n", "        Handle the tool calls from the model response. This function should:\n", "        - Execute the tool calls\n", "        - Append the tool calls and responses to the chat history\n", "\n", "        Args:\n", "            response (ChatCompletionMessage): The response from the model\n", "        \"\"\"\n", "        if self.verbose:\n", "            print(\"\\nTool calls:\", response.tool_calls)\n", "\n", "        # Append response to chat history\n", "        self.chat_history.append(response)\n", "\n", "        # Execute the tool calls and append tool responses to chat history\n", "        tool_calls = response.tool_calls\n", "        try:\n", "            tool_responses = self.execute_tool_calls(response)\n", "            for tool_call, tool_response in zip(tool_calls, tool_responses):\n", "                self.chat_history.append(\n", "                    apply_tool_call_format(tool_call, tool_response)\n", "                )\n", "                if self.verbose:\n", "                    print(f\"\\nTool call: {tool_call.function.name}, ARGS: {tool_call.function.arguments}\")\n", "                    print(f\"Tool response: {tool_response}\")\n", "        except Exception as e:\n", "            print(f\"\\nError handling tool calls: {e}\")\n", "\n", "    def handle_refusal(self, response: ChatCompletionMessage):\n", "        \"\"\"\n", "        Handle the refusal from the model response. This function should only be called if the model refuses to answer and should:\n", "        - Append the refusal to the chat history\n", "        - Update the task state\n", "\n", "        Args:\n", "            response (ChatCompletionMessage): The response from the model\n", "        \"\"\"\n", "        if self.verbose:\n", "            print(\"\\nModel Refusal:\", response.refusal)\n", "        self.chat_history.append(apply_assistant_format(response.refusal))\n", "        self.task.update_current_task()\n", "\n", "    def generate_and_check_final_answer(self) -> Literal[\"Correct\", \"Incorrect\"]:\n", "        \"\"\"\n", "        This function should:\n", "        - Get the model to generate a final answer to the question (after it has seen the tool response)\n", "        - Then check this final answer against the correct answer.\n", "        - If the answer is correct, update the task state.\n", "        - Then append to chat history (and return) \"Correct\" if the answer is correct and \"Incorrect\" if the answer is incorrect.\n", "\n", "        Args:\n", "            None\n", "\n", "        Returns:\n", "            str: \"Correct\" or \"Incorrect\"\n", "        \"\"\"\n", "        # Get the final response from the model after tool responses\n", "\n", "        response = self.get_response(use_tool=False)\n", "        self.chat_history.append(apply_assistant_format(response.content))\n", "\n", "        # Check the answer\n", "        try:\n", "            model_answer = self.parse_answer(response)\n", "\n", "            if self.task.check_answer(model_answer):\n", "                self.chat_history.append(apply_user_format(\"Correct.\"))\n", "\n", "                if self.verbose:\n", "                    print(\"\\nUser: Correct.\")\n", "\n", "                # Update to the next task\n", "                self.task.update_current_task()\n", "\n", "                return \"Correct\"\n", "\n", "            else:\n", "                self.chat_history.append(apply_user_format(\"Incorrect.\"))\n", "                if self.verbose:\n", "                    print(\"\\nUser: Incorrect.\")\n", "                return \"Incorrect\"\n", "                # Retry the task\n", "\n", "        # Ends the task if there's an error parsing the model answer\n", "        except Exception as e:\n", "            if self.verbose:\n", "                print(f\"\\nError parsing model answer: {e}\")\n", "            raise e\n", "\n", "    def run(self, with_tool: bool):\n", "        \"\"\"\n", "        Run one loop of the agent, which involves:\n", "        - getting a task\n", "        - getting a response from the model\n", "        - handling the model response, including tool calls, refusals, no tool calls, parsing and checking final answers, errors.\n", "        - managing memory: storing the history of messages to self.chat_history\n", "        - managing task state: staying on the same task or moving to the next task at the end of the loop\n", "        \"\"\"\n", "        # Get the task instruction\n", "        instruction = self.task.instruction\n", "        if self.verbose:\n", "            print(\"\\nUSER:\", instruction[\"content\"])\n", "        self.chat_history.append(instruction)\n", "\n", "        # Get the response from the model\n", "        response = self.get_response(use_tool=with_tool)\n", "\n", "        if self.verbose:\n", "            print(\"\\nModel response:\", response.content)\n", "\n", "        # Handle the response\n", "        ## If model makes tool calls, handle the tool calls\n", "        if response.tool_calls:\n", "            self.handle_tool_calls(response)\n", "\n", "            # Then get the final answer from the model\n", "            self.generate_and_check_final_answer()\n", "\n", "        ## If no tool call: Handle edge cases\n", "\n", "        ### Check if there's a refusal to answer:\n", "        elif response.refusal:\n", "            self.handle_refusal(response)\n", "\n", "        else:\n", "            self.generate_and_check_final_answer()\n", "\n", "    def parse_answer(self, message: ChatCompletionMessage) -> float:\n", "        \"\"\"\n", "        Extract the numerical answer from the string output of the model\n", "\n", "        Args:\n", "            message (ChatCompletionMessage): The response from the model\n", "\n", "        Returns:\n", "            float: The numerical answer extracted from the model\n", "        \"\"\"\n", "        response = message.content\n", "        if response.find(\"<answer>\") != -1:\n", "            startpoint = response.find(\"<answer>\") + 8\n", "            endpoint = response.find(\"</answer>\")\n", "            return float(response[startpoint:endpoint])\n", "        else:\n", "            raise ValueError('\"<answer>\" not found in model response.')"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Run the task via an agent_loop\n", "\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\u26aa\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\n", "> \n", "> You should spend up to 5-10 minutes on this exercise.\n", "> ```\n", "\n", "Try implementing the agent_loop below with and without tools, to see how much better the model does when we give it tools.\n", "\n", "> **WARNING!** \n", ">\n", ">When you're making API calls to LLMs to tasks, it can be tempting to use a while loop, and run the model until it finishes the task. But since every time we run a model we make an API call, this would allow us to spend arbitrarily large amounts of money on API calls. For this reason, ***always use a for loop when making API calls!!!*** It would be really unfortunate if you blew all your API budget on one mistake."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def agent_loop(agent, num_loops: int = 10):\n", "    \"\"\"\n", "    Run the agent loop for a given number of loops\n", "\n", "    Args:\n", "        agent (ArithmeticAgent): The agent to run\n", "        task (ArithmeticTask): The task to solve\n", "        num_loops (int): The number of loops to run\n", "    \"\"\"\n", "    for i in range(num_loops):\n", "        if not agent.task.check_solved():\n", "            agent.run(with_tool=False)\n", "        else:\n", "            print(\"\\nAll tasks solved.\")\n", "            break\n", "\n", "arithmetic_task_1 = ArithmeticTask(31.1, 8)\n", "arithmetic_agent_1 = ArithmeticAgent(\n", "    task=arithmetic_task_1, verbose=True, tools=[Calculator]\n", ")\n", "\n", "\n", "agent_loop(arithmetic_agent_1)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["If we want to see how the model performed at the task, then we can print all the messages from the `ChatHistory` as follows:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for message in arithmetic_agent_1.chat_history:\n", "    try:\n", "        print(f\"\"\"{str(message.role)}:\\n {str(message.content)}\\n\"\"\")\n", "    except:\n", "        print(f\"\"\" {message[\"role\"]}:\\n {message[\"content\"]}\\n\"\"\")"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 3\ufe0f\u20e3 Building a more complex agent: WikiGame\n", "\n", "> ##### Learning Objectives\n", ">\n", "> - Understand how to build a more complex agent\n", "> - Observe the failure modes of a more complex agent"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Quick Intro to the Wikipedia API\n", "\n", "Our agent will interact with Wikipedia by making tool calls to the [Wikipedia API](https://wikipedia.readthedocs.io/en/latest/quickstart.html), which is simple to use. We will only need to learn the following key functions for the game. \n", "\n", "1. `wikipedia.page()` - Returns a `WikipediaPage` object, which contains various attributes and methods to access page content. (See [page docs](https://wikipedia-api.readthedocs.io/en/latest/API.html#wikipediapage) for these attributes.)\n", "2. `wikipediaPage.title` - Returns the title of the page\n", "3. `wikipediaPage.content` - Returns the full text content of the page (this can be very long, make sure to take snippets when possible to not use up the context window of the LLM)\n", "4. `wikipediaPage.summary` - Returns a summary of the page (i.e. the introductory text of the Wikipage before the first section title).\n", "5. `wikipediaPage.links` - Returns a list of all links as strings\n", "\n", "\n", "<details><summary> Aside: Wikipedia API content can be weird!</summary>\n", "\n", "The wikipedia API often outputs content in unintuitive ways. For example, articles that are essentially just a big list become near useless, since the content omits the list (for example, see the wikipedia API content for <a href = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population\">List of countries and dependencies by population</a>). Another issue that you might encounter is that the API formats mathematical expressions in $\\LaTeX$ pretty poorly (for example, see the wikipedia API content for <a href = \"https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\">Kullback-Leibler divergence</a>). This is why it's important to determine what content the wikipedia API produces when `.content` is called \u2014 and why you want to make sure you're testing a large diversity of wikipedia articles.\n", "\n", "</details>\n", "\n", "<details><summary> Aside: Wikipedia \"summaries\" can be long!</summary>\n", "\n", "The wikipedia API accesses summaries of pages by presenting all the information before the first titled section. For certain (generally obscure) wikipedia pages, this summary itself can be extremely long, and contain lots of information that is unnecessary to determine the key information about the page the model should be trying to access. We'll handle this later when it comes up by truncating wikipedia's summary to just the first ~1000 characters\n", "\n", "</details>\n", "\n", "Run the following code to see how these wikipedia API functions work!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Retrieve a Wikipedia page from its title\n", "page = wikipedia.page(\"Large language model\")\n", "\n", "# Access basic page information\n", "print(\"Title:\", page.title)\n", "print(\"\\nURL\", page.url)\n", "print(f\"\\nSummary (word count {len( page.summary.split())}):\", page.summary)\n", "print(\n", "    f\"\\nContent (word count {len( page.content.split())}):\",\n", "    page.content[:1000],\n", "    \"......\",\n", ")\n", "print(\n", "    f\"\"\"\\nLinks (link count {len(page.links)}): [{\", \".join(page.links[:7])}, ......]\"\"\"\n", ")"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Now run these two lines (you should see a `DisambiguationError` for the first, and a `PageError` for the second):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["page = wikipedia.page(\"Python\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["page = wikipedia.page(\"Animalss\", auto_suggest=False)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["We can handle these errors using the following code:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fixes PageError by allowing redirects\n", "page = wikipedia.page(\"Animalss\", redirect=True)\n", "print(page.title)\n", "\n", "# Fixes DisambiguationError by selecting the first option\n", "\n", "try:\n", "    page = wikipedia.page(\"Python\")\n", "except DisambiguationError as e:\n", "    page = wikipedia.page(e.options[0])\n", "print(page.title)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["- `DisambiguationError`: This was raised because the title \"Python\" can correspond to multiple pages. \n", "- `PageError`: This was raised for \"Animalss\" as there is no Wikipedia page with that title.\n", "\n", "We have implemented a simple function `get_page()` for you to get the page object for a particular page title with error handling."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_page(title: str) -> WikipediaPage:\n", "    \"\"\"\n", "    Get a Wikipedia page object given a title. If the title is ambiguous, choose the first option. If the title is not found, try to find a similar title.\n", "\n", "    Args:\n", "        title (str): The title of the Wikipedia page\n", "\n", "    Returns:\n", "        WikipediaPage: The Wikipedia page\n", "    \"\"\"\n", "    try:\n", "        return wikipedia.page(title, auto_suggest=False, redirect=True)\n", "    except DisambiguationError as e:\n", "        return wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n", "    except PageError as e:\n", "        return wikipedia.page(title, auto_suggest=True, redirect=True)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["<details><summary>What do the kwargs <code>redirect</code> and <code>auto_suggest</code> in <code>wikipedia.page()</code> do?</summary>\n", "\n", "`redirect`\n", "\n", "- This kwarg enables redirecting when you reference an article title with **slight** differences to how it is stored in Wikipedia. For example, the Wikipedia API will generally access the correct page if there is a capitalization error on the first letter, but not for capitalization errors in the middle of the word if `redirect = False`:\n", "```python\n", "# This returns a WikipediaPage object for the \"Human\" page\n", "page = wikipedia.page(\"huMan\", redirect = True, auto_suggest=False)\n", "\n", "# This raises a PageError since there is no page called \"huMan\"\n", "page = wikipedia.page(\"huMan\", redirect=False, auto_suggest=False)\n", "```\n", "- By default, we should set `redirect = True` in the `wikipedia.page()` function.\n", "\n", "`auto_suggest`\n", "\n", "- This kwarg enables the API to provide suggestions. This allows a lot more than `redirect` does, since `redirect` is only for the \"obvious\" cases (e.g. \"huMan\" \u2192 \"Human\", \"U.S. President\" \u2192 \"President of the United States\", etc.). When `auto_suggest` is true, it would allow something like \"president of states\" \u2192 \"President of the United States\", \"gogle\" \u2192 \"Google\"; both of which would raise an error if `redirect = True, auto_suggest = False`.\n", "- However, `auto_suggest` can sometimes be *too* permissive and lead to errors. For example, the below code will return a `WikipediaPage` object for the \"Man\" page. This is clearly not what we were trying to access, and the `auto_suggest` has gotten carried away in this case:\n", "\n", "```python\n", "page = wikipedia.page(\"Human\", redirect= False, auto_suggest=True)\n", "```\n", "\n", "- If `redirect = True` and `auto_suggest=True`, then `auto_suggest` takes priority. \n", "- **By default, we should set `auto_suggest` to `False` unless it is used as a last resort to resolve an error!**\n", "\n", "</details>"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement `get_permitted_links()`\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\u26aa\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> \n", "> You should spend up to ~10 mins on this exercise.\n", "> ```\n", "\n", "This is a quick exercise to familarize you with the Wikipedia API.\n", "\n", "When you get the links from a page using `page.links`, this will include every possible Wikipedia link that is accessible from the HTML on that page, including those that are not in the main page content (e.g. links in sidebars, links in footnotes etc.), which are irrelevant or not permitted by the rules of the Wiki game. \n", "\n", "Write a simple `get_permitted_links()` function. This should only return the links that can be found inside the main content. The resulting list of permitted links should be about a third as long as the list of links from `page.links`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_permitted_links(current_page: WikipediaPage) -> list[str]:\n", "    \"\"\"\n", "    Get \"permitted\" links (i.e. links that are in the content of the page) from a Wikipedia page.\n", "\n", "    Args:\n", "        current_page (WikipediaPage): The current Wikipedia page\n", "\n", "    Returns:\n", "        list[str]: A list of permitted links from current_page\n", "\n", "    \"\"\"\n", "    all_links = current_page.links\n", "    content_lower = current_page.content.lower()\n", "    permitted_links = [link for link in all_links if link.lower() in content_lower]\n", "    return permitted_links"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## LLM Agent for WikiGame\n", "\n", "<img src=\"https://raw.githubusercontent.com/info-arena/ARENA_img/refs/heads/main/img/ch3-wiki-task-overview.png\" width=\"1000\">"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Build the WikiGame task\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\n", "> \n", "> You should spend up to 10-15 mins on this exercise.\n", "> ```\n", "\n", "Build the `WikiGame` class that instantiates the wikipedia game. This should contain the following functionalities:\n", "1. Keep track of task states\n", "2. Give task-specific instructions\n", "3. Task-specific helper functions for calling the Wikipedia API. These less interesting methods have been provided for you, but you should read and understand what they do.\n", "\n", "#### Providing information to the agent\n", "\n", "While models are trained on most of the Wikipedia content, a particular page may still be confused with something else, or be an article that was added after the training cutoff. Models also can't always accurately recall information in their training data if they only come up once or twice. So you should use the game's `get_summary()` function to provide details of the goal page to the agent in its initial message."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WikiGame:\n", "    def __init__(\n", "        self,\n", "        starting_page: str,\n", "        goal_page: str,\n", "    ):\n", "        \"\"\"\n", "        Initialize the Wikipedia game object.\n", "\n", "        Args:\n", "            starting_page (str): The page the agent starts on.\n", "            goal_page (str): The page the agent is trying to reach.\n", "        \"\"\"\n", "        self.page_history: List[str] = [starting_page]\n", "        self.starting_page: WikipediaPage = self.get_page(starting_page)\n", "        self.goal_page: WikipediaPage = self.get_page(goal_page)\n", "        self.current_page: WikipediaPage = self.starting_page\n", "\n", "    # ========================= Helper Functions (given) =========================\n", "\n", "    # Get page and page summary\n", "    @staticmethod\n", "    def get_page(title: str) -> WikipediaPage:\n", "        \"\"\"\n", "        Get a Wikipedia page object given a title. If the title is ambiguous, choose the first option. If the title is not found, try to find a similar title.\n", "\n", "        Args:\n", "            title (str): The title of the Wikipedia page\n", "\n", "        Returns:\n", "            WikipediaPage: The Wikipedia page\n", "        \"\"\"\n", "        try:\n", "            return wikipedia.page(title, auto_suggest=False, redirect=True)\n", "        except DisambiguationError as e:\n", "            return wikipedia.page(e.options[0], auto_suggest=False, redirect=True)\n", "        except PageError as e:\n", "            return wikipedia.page(title, auto_suggest=True, redirect=True)\n", "\n", "    def get_page_summary(self, page: WikipediaPage | None = None) -> str:\n", "        \"\"\"\n", "        Get summary of a wikipedia page, to the last full stop within the first 500 characters. This is used to give a brief overview of the page to the agent.\n", "\n", "        Args:\n", "            page (WikipediaPage): The Wikipedia page object.\n", "\n", "        Returns:\n", "            str: The summary of the Wikipedia page.\n", "        \"\"\"\n", "        page = page if page else self.goal_page\n", "        summary = page.content[:500]\n", "        last_period_index = summary.rfind(\".\")\n", "        return summary[: last_period_index + 1] if last_period_index != -1 else summary\n", "\n", "    # Get and check permitted links\n", "    def get_permitted_links(self, title: Optional[str] = None) -> list[str]:\n", "        \"\"\"\n", "        Returns a list of permitted links (i.e. links in the main page content) for the current page.\n", "\n", "        Args:\n", "            title (Optional[str]): The title of the Wikipedia page. If None, uses the current page.\n", "\n", "        Returns:\n", "            list[str]: The permitted links.\n", "        \"\"\"\n", "        if title:\n", "            page = self.get_page(title)\n", "            all_links = page.links\n", "            content = page.content\n", "            permitted_links = [link for link in all_links if link in content]\n", "            if title in permitted_links:\n", "                permitted_links.remove(title)\n", "        else:\n", "            all_links = self.current_page.links\n", "            content = self.current_page.content\n", "            permitted_links = [link for link in all_links if link in content]\n", "            if self.current_page.title in permitted_links:\n", "                permitted_links.remove(self.current_page.title)\n", "        return permitted_links\n", "\n", "    def is_permitted_link(self, link: str) -> bool:\n", "        \"\"\"\n", "        Returns True if the link is in the permitted links for the current page, False otherwise.\n", "\n", "        Args:\n", "            link (str): The link to check.\n", "\n", "        Returns:\n", "            bool: True if the link is permitted, False otherwise\n", "        \"\"\"\n", "        return link.lower() in (x.lower() for x in self.get_permitted_links())\n", "\n", "    # ========================= Task State Management (to implement) =========================\n", "\n", "    @property\n", "    def system_instruction(self) -> dict:\n", "        \"\"\"\n", "        Generate the starting instructions for the game, formatted as a system prompt.\n", "\n", "        Returns:\n", "            dict: The starting instructions.\n", "        \"\"\"\n", "        return apply_system_format(\"You are a wikipedia-racing AI. Your aim is to reach the goal page by accessing links from a series of wikipedia pages.\")\n", "    @property\n", "    def on_page_instruction(self) -> dict:\n", "        \"\"\"\n", "        Tell the agent what page they are on and give a summary of the page, formatted as a user prompt.\n", "\n", "        Returns:\n", "            dict: The instructions for the current page.\n", "        \"\"\"\n", "        return apply_user_format(f\"\"\"You are currently on page: {self.current_page.title}. Your goal page is {self.goal_page.title}.\"\"\")\n", "    @property\n", "    def next_step_instruction(self) -> dict:\n", "        \"\"\"\n", "        Ask the agent \"What's the next step?\" after making a tool call, formatted as a user prompt.\n", "\n", "        Returns:\n", "            dict: The instructions for the next step.\n", "        \"\"\"\n", "        return apply_user_format(f\"What's your next step?\")\n", "\n", "    def check_win(self) -> bool:\n", "        return self.current_page == self.goal_page"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Build tools for the WikiGame\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\u26aa\n", "> \n", "> You should spend up to 15-20 mins on this exercise.\n", "> ```\n", "\n", "The basic WikiAgent will need these two tools at minimum to play the game:\n", "1. `GetContentTool`: This returns the full content of the current page, with all the wiki-links wrapped in `<link></link>` tags (as otherwise they are presented as strings and indistinguishable from normal text). As implementing this involves annoying regex, we have done this for you, but you should fill in the `description()` property.\n", "2. `MovePageTool`: This executes moving to a new given page when called and updates the `WikiGame` task state if successful. You should implement both the `execute()` function and the `description()` property.\n", "\n", "When formatting this tool list, refer back to your code for the arithmetic game, or the OpenAI function-calling docs [here](https://platform.openai.com/docs/guides/function-calling).\n", "\n", "<details><summary>Why not just use <code>WikipediaPage.links()</code> to get a list of links directly?</summary>\n", "\n", "We don't just present a list of the accessible links, as this is not very faithful to the wikipedia game. The agent does perform somewhat better if we just give it a list of links, but the task of parsing the content of wikipedia pages and isolating the most important links is big part of the challenge of the wikipedia game.\n", "\n", "</details>\n", "\n", "<details><summary>Caveat for the <code>GetContentTool</code></summary>\n", "\n", "The `GetContentTool` wraps all the texts that correspond to links in `<link></link>` tags. However, since we identify links in the text via their names on wikipedia pages, there are certain articles that will never (or only very rarely) get flagged as links. For example, the page \"Python (programming language)\" is almost never referenced by its title, instead its almost always referenced by just \"Python\"; the same is true for towns, which are usually referenced on Wikipedia as e.g. \"Juneau, Alaska\", but these are almost always referred to as just \"Juneau\" in the articles where they appear. For this reason, you should avoid having goal pages which are not referenced by their title (or else implement a better version of the function, but beware of simply extracting the HTML source from pages, `wikipediaPage.html` can take a very long time to run, and HTML formatting can vary significantly across Wikipedia).\n", "\n", "</details>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GetContentTool():\n", "    name = \"get_content\"\n", "\n", "    @staticmethod\n", "    def execute(task: WikiGame) -> str:\n", "        \"\"\"\n", "        Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link is wrapped in <link></link> tags.\n", "\n", "        Args:\n", "            task (WikiGame): The current task object.\n", "\n", "        Returns:\n", "            str: The content of the page with links wrapped\n", "        \"\"\"\n", "        content = task.current_page.content\n", "        permitted_links = get_permitted_links(task.current_page)\n", "        for word in sorted(permitted_links, key=len, reverse=True):\n", "            content = re.sub(\n", "                r\"\"\"(\\s|[,.)!?;:'\"])(\"\"\" + re.escape(word) + r\"\"\")(\\s|[,.)!?;:'\"s])\"\"\",\n", "                r\"\\1<link>\\2</link>\\3\",\n", "                content,\n", "                count=1,\n", "                flags=re.IGNORECASE,\n", "            )\n", "        return content\n", "\n", "    @property\n", "    def description(self):\n", "        \"\"\"\n", "        Provides the description of the getContent tool\n", "\n", "        Returns:\n", "            dict: The description of the tool for the API\n", "        \"\"\"\n", "        return {\n", "            \"type\": \"function\",\n", "            \"function\": {\n", "                \"name\": self.name,\n", "                \"description\": \"Get all the content for the wikipedia page you are currently on. Anything which corresponds to a link you can select to move to will be wrapped in <link></link> tags.\",\n", "                \"parameters\": {\n", "                    \"type\": \"object\",\n", "                    \"properties\": {},\n", "                    \"required\": [],\n", "                },\n", "            },\n", "        }\n", "\n", "\n", "class MovePageTool():\n", "    name = \"move_page\"\n", "\n", "    @staticmethod\n", "    def execute(new_page: str, task: WikiGame) -> str:\n", "        \"\"\"\n", "        Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n", "\n", "        Args:\n", "            task (WikiGame): The current task object.\n", "            new_page (str): The title of the new page to move to.\n", "\n", "        Returns:\n", "            str: A message indicating the result of the move\n", "        \"\"\"\n", "        new_page_normalized = new_page.replace(\"_\", \" \")\n", "        if task.is_permitted_link(new_page_normalized):\n", "            task.current_page = task.get_page(new_page_normalized)\n", "            task.page_history.append(task.current_page.title)\n", "            return f\"Moving page to {task.current_page.title}\"\n", "        else:\n", "            return f\"Couldn't move page to {new_page}. This is not a valid link.\"\n", "\n", "    @property\n", "    def description(self):\n", "        \"\"\"\n", "        Provides the description of the move_page tool\n", "\n", "        Returns:\n", "            dict: The description of the move_page tool for the API\n", "        \"\"\"\n", "        return {\n", "            \"type\": \"function\",\n", "            \"function\": {\n", "                \"name\": self.name,\n", "                \"description\": \"Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\",\n", "                \"parameters\": {\n", "                    \"type\": \"object\",\n", "                    \"properties\": {\n", "                        \"new_page\": {\n", "                            \"type\": \"string\",\n", "                            \"description\": 'The title of the new page you want to move to. This should be formatted the way the title appears on wikipedia (e.g. to move to the wikipedia page for the United States of America, you should enter \"United States\"). Underscores are not necessary.',\n", "                        }\n", "                    },\n", "                    \"required\": [\"new_page\"],\n", "                },\n", "            },\n", "        }  \n", "\n", "GetContentTool_inst = GetContentTool()\n", "MovePageTool_inst = MovePageTool()\n", "wiki_game_tools = [GetContentTool_inst, MovePageTool_inst]"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Build a WikiAgent\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\ud83d\udd35\n", "> \n", "> You should spend up to 30-60 mins on this exercise.\n", "> ```\n", "\n", "We will now build a `WikiAgent` that can use these tools to solve the `WikiGame`. Build the agent so that it can be called via an agent loop, similar to the one we had for the arithmetic game. \n", "\n", "There are a few further considerations in this case that we didn't have for the arithmetic game. \n", "\n", "#### Context window constraint\n", "\n", "Since Wikipedia articles could be very long, the length of the LLM's context window becomes a constraint. GPT-4o and GPT-4o-mini both have context windows of 128k tokens (which corresponds to ~96k words). For reference, the wikipedia page for the United States has around 10k words alone and the agent will often need to visit more than 10 articles in one run of the game, not counting its own output, which eventually adds up to be significant. \n", "\n", "We'll solve this for now by simply resetting the messages of the agent every time it reaches a new wikipedia page, and providing an updated set of instructions, so the agent can locate itself in the game. We'll address different methods for solving this issue later, you can probably already think of some. So be careful to include the current page and goal page for the agent in the instruction.\n", "\n", "Since we'll reset the `chat_history` attribute of the agent class each time it reaches a new page, we'll also store a `full_chat_history` property that won't get reset, so we can access the entire run of the game.\n", "\n", "\n", "#### Printing output\n", "\n", "The `WikiGame` is a lot longer than the `ArithmeticTask`, with a much larger volume of agent, task and tool messages. If there's some chance you might not want to see this output, you should use the `verbose` parameter to set whether to print the output or not."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WikiAgent(SimpleAgent):\n", "    \"\"\"\n", "    Inherits from SimpleAgent and adds the ability to handle tool calls and refusals in the Wikipedia game context.\n", "\n", "    Attributes:\n", "        model (str): The model used for generating responses (inherited)\n", "        tools (List[Any]): List of tools (inherited)\n", "        client (OpenAI): OpenAI client for API calls (inherited)\n", "        task (WikiGame): The current task being executed\n", "        chat_history (List[dict]): History of interactions (inherited)\n", "\n", "    Methods:\n", "        get_response(use_tool: bool = True) -> ChatCompletionMessage:\n", "            Get response from the model (inherited)\n", "\n", "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]:\n", "            Execute tool calls from the model's response (inherited)\n", "\n", "        run(with_tool: bool = True) -> bool:\n", "            Run one loop of the Wikipedia agent (modified below)\n", "\n", "    \"\"\"\n", "\n", "    def __init__(\n", "        self,\n", "        task: WikiGame,\n", "        tools: List[Any],\n", "        model=\"gpt-4o-mini\",\n", "        chat_history: List[dict] = None,\n", "        verbose: bool = True,\n", "    ):\n", "        super().__init__(model=model, tools=tools, task=task)\n", "\n", "        self.chat_history = chat_history if chat_history else []\n", "        self.full_chat_history = (\n", "            chat_history if chat_history else []\n", "        )  # All messages that have been sent in the chat history. We have to erase each time a new page is reached for context window reasons.\n", "        self.verbose = verbose\n", "        self.start()\n", "\n", "    def update_history(\n", "        self, message: dict[str,str] | ChatCompletionMessage | List[dict[str,str] | ChatCompletionMessage]\n", "    ):\n", "        \"\"\"\n", "        Update self.chat_history and self.full_chat_history with a message or list of messages.\n", "\n", "        Args:\n", "            message (dict[str, str] | ChatCompletionMessage | List[dict[str,str] | ChatCompletionMessage]): The message to add to the chat history\n", "        \"\"\"\n", "        if isinstance(message, list):\n", "            self.chat_history.extend(message)\n", "            self.full_chat_history.extend(message)\n", "        else:\n", "            self.chat_history.append(message)\n", "            self.full_chat_history.append(message)\n", "    def reset_history(self):\n", "        \"\"\"\n", "        Empty self.chat_history of the agent.\n", "        \"\"\"\n", "        self.chat_history = []\n", "\n", "    def handle_tool_calls(self, response: ChatCompletionMessage):\n", "        \"\"\"\n", "        Handles tool_calls in the wikipedia game context:\n", "            - Executes the tool calls using execute_tool_calls\n", "            - Appends the original tool call & tool_responses to the chat_history\n", "            - If the agent has moved to a new page, resets the chat_history\n", "            - If not, get the next_step_message instruction from the task and append it to chat_history\n", "\n", "        Args:\n", "            response (ChatCompletionMessage): The response from the model\n", "        \"\"\"\n", "        # Update history\n", "        self.update_history(response)\n", "\n", "        # Execute the tool calls\n", "        tool_responses = self.execute_tool_calls(response)\n", "\n", "        # Add tool calls and responses to the history\n", "        for tool_call, tool_response in zip(response.tool_calls, tool_responses):\n", "            self.update_history(apply_tool_call_format(tool_call, tool_response))\n", "\n", "            if self.verbose:\n", "                print(\n", "                    f\"\\nTOOL CALL: \\nTool = {tool_call.function.name}, Args = {tool_call.function.arguments} \\nTOOL RESPONSE:\\n {tool_response[:300]}\"\n", "                )\n", "\n", "        # Move to new page if necessary\n", "        if any(\"Moving page\" in tool_response for tool_response in tool_responses):\n", "            self.reset_history()\n", "            print(\n", "                f\"\"\"{(\"-\" * 50)} \\n\\nMOVED TO PAGE \\n\\nPATH HISTORY (N={len(self.task.page_history)}): {\" -> \".join(self.task.page_history)} \\n\\n{(\"-\"*50)}\"\"\"\n", "            )\n", "\n", "            # Give starting instructions if moved to a new page\n", "            self.start()\n", "\n", "        # Otherwise ask the agent what the next step is\n", "\n", "        else:\n", "            next_step_message = self.task.next_step_instruction\n", "            self.update_history(next_step_message)\n", "            if self.verbose:\n", "                print(f\"\"\"\\nUSER: \\n{next_step_message[\"content\"]}\"\"\")\n", "\n", "    def handle_refusal(self, response: ChatCompletionMessage):\n", "        \"\"\"\n", "        Handles refusals in the wikipedia game context:\n", "\n", "        Args:\n", "            response (ChatCompletionMessage): The response from the model\n", "        \"\"\"\n", "        self.update_history(apply_assistant_format(response.refusal))\n", "        if self.verbose:\n", "            print(f\"\\nMODEL REFUSAL: {response.refusal}\")\n", "\n", "    def start(self):\n", "        \"\"\"\n", "        A function to put the starting instructions in agent.chat_history when the agent starts a new page or starts the game.\n", "        \"\"\"\n", "        instruction_messages = [\n", "            self.task.system_instruction,\n", "            self.task.on_page_instruction,\n", "        ]\n", "        self.update_history(instruction_messages)\n", "        if self.verbose:\n", "            print(\n", "                f\"\\nSYSTEM: \\n{instruction_messages[0]['content']} \\n\\nUSER: \\n{instruction_messages[1]['content']}\"\n", "            )\n", "\n", "    def run(self):\n", "        \"\"\"\n", "        This function runs the agent in the wikipedia game context. It:\n", "            - Gets the current task instruction\n", "            - Gets the response from the model\n", "            - Handles the response in the cases:\n", "                - tool calls (using handle_tool_calls)\n", "                - refusals (using handle_refusal)\n", "                - no tool calls (using update_history)\n", "        \"\"\"\n", "        # Get the response from the model\n", "        response = self.get_response()\n", "\n", "        # Handle the response\n", "        ## If tool calls, do the tool calls and return the response\n", "        if response.tool_calls:\n", "            self.handle_tool_calls(response)\n", "\n", "        ## If no tool call: Handle edge cases\n", "        ### Check if there's a refusal to answer:\n", "        elif response.refusal:\n", "            self.handle_refusal(response)\n", "\n", "        # Else response content does not contain tool calls or refusal, and we add it to the chat_history in an assistant format.\n", "        else:\n", "            self.update_history(apply_assistant_format(response.content))\n", "            if self.verbose:\n", "                print(f\"\\nMODEL RESPONSE: \\n{response.content}\")"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Run the task\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> \n", "> You should spend up to 10-15 mins on this exercise.\n", "> ```\n", "\n", "Similar to the `ArithmeticAgent`, write an agent loop for the `WikiAgent`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def agent_loop(agent, num_loops=10):\n", "    \"\"\"\n", "    Run the agent loop for a given number of loops\n", "\n", "    Args:\n", "        agent (WikiAgent): The agent to run\n", "        game (WikiGame): The game to play\n", "        num_loops (int): The number of loops to run\n", "    \"\"\"\n", "    for i in range(num_loops):\n", "        if agent.task.check_win():\n", "            print(\"Success!\")\n", "            return\n", "        agent.run()"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Your agent should be able to accomplish the following tasks:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["game_1 = WikiGame(\"Barack Obama\", \"India\")\n", "agent = WikiAgent(task=game_1, tools=wiki_game_tools)\n", "agent_loop(agent, game_1, 30)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["game_2 = WikiGame(\"Albert Einstein\", \"Aristotle\")\n", "agent = WikiAgent(task=game_2, tools=wiki_game_tools)\n", "agent_loop(agent, game_2, 30)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Once you've seen that the agent can accomplish the above, try out some different articles and see where the agent fails.\n", "\n", "Check the messages in the chat history to see the full conversation between the agent and the user, to ensure that the messages that are printed above are faithful to the actual chat history (it can be easy to make minor mistakes that mess up the agent's `chat_history`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for message in agent.chat_history:\n", "    try:\n", "        print(f\"{str(message.role)}:\\n {str(message.content)}\")\n", "    except:\n", "        print(f\"\"\"{message[\"role\"]}:\\n {message[\"content\"]}\"\"\")"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 4\ufe0f\u20e3 Elicitation\n", "\n", "> ##### Learning Objectives\n", ">\n", "> - Understand the different methods of elicitation\n", "> - Understand how to improve prompting, tools, history storage, and information access in LLM agents"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["You may have observed that while the above implementation of `WikiAgent` succeeds at Albert Einstein \u2192 Aristotle, it fails at more difficult tasks. However, this doesn't mean that GPT-4o-mini does not have the capability to perform better on this task, but this capability might be blocked because we:\n", "\n", "- Prompted the model poorly\n", "- Stored the history poorly\n", "- Didn't give the model sufficient tools to accomplish the task.\n", "- ...\n", "\n", "In general, it is hard to show that a model does not have a capability, even if we failed to demonstrate this capability. For example, it took 3.5 years after the release of GPT-2 (and 2.5 years after the release of GPT-3) for people to discover that [chain-of-thought reasoning](https://arxiv.org/abs/2201.11903) massively improves model performance, which enabled the same models to complete significantly harder tasks. LLM agent evals aim to elicit the best capability we possibly can, until we feel we've managed to gain [**evidence of absence**](https://en.wikipedia.org/wiki/Evidence_of_absence), **not** just **absence of evidence**.\n", "\n", "\n", "Broadly speaking, there are two categories of elicitation:\n", "\n", "1. **Narrow elicitation**: Task-specific methods that improve model performance on a particular task or small class of tasks, but likely won't impact model performance in general across many tasks. \n", "    - E.g. A tool that gives the model access to the content of arbitrary wikipedia articles. This will improve performance on this task significantly, but wouldn't generalize to other tasks.\n", "2. **General elicitation**: Task-agnostic methods that improve model performance on a wide array of possible tasks. \n", "    - E.g. Chain-of-thought prompting: This tends to improve model performance on a wide array of tasks. These sorts of elicitation methods are the ones we're most interested in, as if researchers find an improvement to models that is roughly as easy and effective as chain-of-thought prompting, then we would see a very rapid increase in risk from AI.\n", "\n", "\n", "We will try the following elicitation methods in this section:\n", "1. Prompt engineering, including:\n", "    - Chain-of-thought prompting\n", "    - The ReAct framework\n", "2. Reflexion, which allows the model to cheaply explore future paths\n", "3. Improved message histories\n", "\n", "Then you will be able to try further elicitation methods, including any of your own, as a bonus.\n", "\n", "<details><summary>Tip - How to find wikipedia pages to test on</summary>\n", "\n", "You might start having a hard time coming up with wikipedia pages to test on. Luckily, Wikipedia offers a random page link, which is accessible via: https://en.wikipedia.org/wiki/special:random. \n", "\n", "If the pages are *too* random and not connected by links, try the \"special:random\" link to a different language's wikipedia (which is sparser and contains more popular/well-connected pages). **Make sure to check this page exist in English!**\n", "\n", "To test whether two pages are connect via links, use this free online tool to see the possible paths between pages: https://www.sixdegreesofwikipedia.com/ (be somewhat careful with this though, as the paths that this website believes are accessible may not be accessible to our agent). \n", "\n", "</details>"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Prompting\n", "\n", "As you should already know, prompting can have a large impact on model performance. There are many changes you could make for prompts in this task. You should experiment first with more general elicitation methods such as getting the agent to think more deeply, and output plans in different ways. After this, you might try more narrow elicitation methods, such as:\n", "\n", "- Telling the agent how many pages it's visited.\n", "- Telling the agent if it's already visited the page it's on (and how many times).\n", "- Schedule different prompts and planning methods for the \"zoom out\" and \"zoom in\" sections of the game, since we know that the general strategy for the wikipedia game looks like:\n", "\n", "   `Narrow article (with few links) -> General article (with many links) -> Narrow article (with few links)`"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Engineer prompts\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\u26aa\n", "> \n", "> You should spend up to 20-35 mins on this exercise.\n", "> ```\n", "Try and design prompts that improve the performance of the wikipedia agent. You may have to do a decent amount of experimentation here. Remember that your prompts will have to be robust to: \n", "\n", "* Different tasks within the wikipedia game, \n", "* Different states within those tasks,\n", "* Different failure-modes the agent could encounter.\n", "\n", "See if you can significantly improve performance. There's a test task below that you should aim to be able to solve with improved prompting."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WikiGamePrompting(WikiGame):\n", "    \"\"\"\n", "    Inherits from WikiGame and adds improved prompting.\n", "\n", "    Attributes:\n", "        starting_page (str): The title of the starting page (inherited)\n", "        goal_page (str): The title of the goal page (inherited)\n", "        current_page (WikipediaPage): The current Wikipedia page (inherited)\n", "        page_history (List[str]): The history of pages visited (inherited)\n", "\n", "    Methods:\n", "        get_page(title: str) -> WikipediaPage: Get a Wikipedia page object given a title (inherited)\n", "\n", "        get_page_summary(page: WikipediaPage | None = None) -> str: Get the summary of a Wikipedia page (inherited)\n", "\n", "        get_permitted_links(title: Optional[str] = None) -> list[str]: Get permitted links for the current page (inherited)\n", "\n", "        is_permitted_link(link: str) -> bool: Check if a link is permitted (inherited)\n", "\n", "        system_instruction -> dict: Generate the starting instructions for the game (modified below)\n", "\n", "        on_page_instruction -> dict: Generate instructions for the current page (modified below)\n", "\n", "        next_step_instruction -> dict: Generate instructions for the next step (modified below)\n", "\n", "        check_win() -> bool: Check if the game has been won (inherited)\n", "\n", "    \"\"\"\n", "\n", "    @property\n", "    def system_instruction(self):\n", "        \"\"\"\n", "        Provide improved starting instructions for the game.\n", "\n", "        Returns:\n", "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n", "        \"\"\"\n", "        return {\n", "            \"role\": \"system\",\n", "            \"content\": f\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}.\",\n", "        }\n", "\n", "    @property\n", "    def on_page_instruction(self):\n", "        \"\"\"\n", "        Provide improved instructions for the current page.\n", "\n", "        Returns:\n", "            dict: The instructions for the current page. \"role\" is \"user\" for user messages.\n", "        \"\"\"\n", "        return {\n", "            \"role\": \"user\",\n", "            \"content\": f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary:\\n\\n[Begin Summary]\\n{self.get_page_summary(self.goal_page)}\\n[End Summary]\\n\\nThe path you have taken so far is {\" -> \".join(self.page_history)}.\n", "            \"\"\",\n", "        }\n", "\n", "    @property\n", "    def next_step_instruction(self):\n", "        \"\"\"\n", "        Provide improved instructions for the next step.\n", "\n", "        Returns:\n", "            dict: The instructions for the next step. \"role\" is \"user\" for user messages.\n", "        \"\"\"\n", "        return {\n", "            \"role\": \"user\",\n", "            \"content\": f\"\"\"What's your next step?\"\"\",\n", "        }"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Your original `WikiGame` and `WikiAgent` may not work on the example path \"Linux\" -> \"Dana Carvey\". But with sufficiently improved prompting, you should be able to get the agent to solve this task!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Original WikiGame and WikiAgent\n", "game = WikiGame(\"Linux\", \"Dana Carvey\")\n", "agent = WikiAgent(game, model=\"gpt-4o-mini\", tools=wiki_game_tools)\n", "agent_loop(agent, game, 30)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#Improved WikiGame and WikiAgent\n", "game = WikiGamePrompting(\"Linux\", \"Dana Carvey\")\n", "agent = WikiAgent(game, model=\"gpt-4o-mini\", tools=wiki_game_tools)\n", "agent_loop(agent, game, 30)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement the ReAct framework\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\u26aa\n", "> \n", "> You should spend up to 15-20 mins on this exercise.\n", "> ```\n", "The [**ReAct** framework](https://arxiv.org/abs/2210.03629) is an extension of chain-of-thought reasoning. In addition to prompting the model to simply think step-by-step, it separates this into two steps:\n", "\n", "- **Re**asoning: The model is asked to reason about its current situation, and what sort of actions it should consider taking.\n", "- **Act**ion: Then, the model is asked to perform an action based on its outputted reasoning.\n", "\n", "Note that during the reasoning step, when you're calling the model without tools, OpenAI won't provide the model with a description of the tools. However, we still want the model to have information on its available tools when it's reasoning about what actions to take. Thus, we'll have to ensure that the tool descriptions are in the `system_instruction` we provide. (This will lead to some redundancy when the model takes an action, but this seems to be okay). This means that from now on we will have to pass the tools to both the *task* and the *agent*."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WikiAgentReAct(WikiAgent):\n", "    \"\"\"\n", "    Inherits from WikiAgent and adds the ReAct framework.\n", "\n", "    Attributes:\n", "        model (str): The model used for generating responses (inherited)\n", "        client (OpenAI): OpenAI client for API calls (inherited)\n", "        task (WikiGame): The current task being executed (inherited)\n", "        chat_history (List[dict]): History of interactions (inherited)\n", "        tools (List[Any]): List of tools (implemented below)\n", "\n", "    Methods:\n", "        get_response(use_tool: bool = True) -> ChatCompletionMessage: Get response from the model (inherited)\n", "\n", "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]: Execute tool calls from the model's response (inherited)\n", "\n", "        run(with_tool: bool = True) -> bool: Run one loop of the Wikipedia agent (inherited)\n", "\n", "        update_history(message : dict[str, str] | ChatCompletionMessage | List[dict[str, str] | ChatCompletionMessage]): Update self.chat_history and self.full_chat_history with a message or list of messages. (inherited)\n", "\n", "        reset_history(): Empty self.chat_history of the agent. (inherited)\n", "\n", "        handle_tool_calls(response: ChatCompletionMessage): Handles tool_calls in the wikipedia game context. (inherited)\n", "\n", "        handle_refusal(response: ChatCompletionMessage): Handles refusals in the wikipedia game context. (inherited)\n", "\n", "        start(): A function to put the starting instructions in agent.chat_history when the agent starts a new page or starts the game. (inherited)\n", "\n", "        run(): This function runs the agent in the wikipedia game context. (inherited)\n", "\n", "\n", "    \"\"\"\n", "    def __init__(self, starting_page: str, goal_page: str, tools=None):\n", "        self.tools = tools\n", "        super().__init__(starting_page, goal_page)\n", "\n", "    @property\n", "    def system_instruction(self):\n", "        \"\"\"\n", "        Provided a description of the tools in the system message. When generate is called with tools this is redundant, but when generate is called without tools, this is useful.\n", "\n", "        Returns:\n", "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n", "        \"\"\"\n", "        tool_descriptions = \"\\n\".join([tool.description[\"function\"][\"name\"] + \":\" + tool.description[\"function\"][\"description\"] for tool in self.tools])\n", "        return {\n", "            \"role\": \"system\",\n", "            \"content\": f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tools))} tools, which are:\\n{tool_descriptions}\"\"\",\n", "        }\n", "\n", "\n", "    def generate_reason(self) -> ChatCompletionMessage:\n", "        \"\"\"\n", "        Generate a reason for the agent to take an action. This function should:\n", "            - Get the model to reason about the current state of the game (without tools)\n", "            - Return the response from the model\n", "\n", "        Returns:\n", "            message (ChatCompletionMessage): The response from the model\n", "        \"\"\"\n", "        # Get the model to reason about the current state of the game and add the response to the messages (you may not want to give it tools for this)\n", "        self.chat_history.append(\n", "            apply_user_format(\n", "                \"Think carefully about your current situation and what actions you want to take to get closer to\"\n", "                + self.task.goal_page.title\n", "                + \".\"\n", "            )\n", "        )\n", "        response = self.get_response(use_tool=False)\n", "        return response\n", "\n", "    def generate_action(self) -> ChatCompletionMessage:\n", "        \"\"\"\n", "\n", "        Generate an action for the agent to take. This function should:\n", "            - Get the model to generate an action for the agent to take (with tools)\n", "            - Return the response from the model\n", "\n", "        Returns:\n", "            message (ChatCompletionMessage): The response from the model\n", "\n", "        \"\"\"\n", "        # Get the model to generate an action based on the reasoning and add the response to the messages\n", "        self.chat_history.append(apply_user_format(\"What action do you want to take?\"))\n", "        response = self.get_response(use_tool=True)\n", "        return response\n", "\n", "    def generate_reason_and_action(self) -> ChatCompletionMessage:\n", "        \"\"\"\n", "\n", "        Generate a Reason and Action for the agent to take. This function should:\n", "            - Generate a Reason\n", "            - Add the Reason to the chat history\n", "            - Generate an Action\n", "            - Return the Action so that tool calls can be handled\n", "\n", "        Returns:\n", "            message (ChatCompletionMessage): The action from the model\n", "        \"\"\"\n", "        reason = self.generate_reason()\n", "        self.update_history(apply_assistant_format(reason.content))\n", "        print(\"\\nModel response ('Reason'):\", reason.content)\n", "\n", "        action = self.generate_action()\n", "\n", "        return action\n", "\n", "    def run(self):\n", "        \"\"\"\n", "        Run one loop of the agent.\n", "\n", "        This function should:\n", "            - Generate a Reason and Action\n", "            - Handle the tool calls, refusals, and no tool calls in the model response\n", "        \"\"\"\n", "        response = self.generate_reason_and_action()\n", "\n", "        if response.tool_calls:\n", "            self.handle_tool_calls(response)\n", "        elif response.refusal:\n", "            self.handle_refusal(response)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["You may have to rewrite your `agent_loop` function (depending on how you implemented it originally)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def agent_loop_ReAct(agent, num_loops = 10):\n", "    \"\"\"\n", "    Run the agent loop for a given number of loops with the ReAct framework.\n", "\n", "    Args:\n", "        agent (WikiAgentReAct): The agent to run\n", "        game (WikiGamePrompting): The game to play\n", "        num_loops (int): The number of loops to run\n", "    \"\"\"\n", "    for i in range(num_loops):\n", "        if agent.task.check_win():\n", "            print(\"Success\")\n", "            return\n", "        agent.run()"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Your `WikiAgent` and `WikiGamePrompting` with only improved prompting might not be able to solve \"Drupe\" \u2192 \"17th parallel north\" (or might not be able to solve it very effectively or reliably). However, your ReAct agent should be able to solve this path."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# WikiGame and WikiAgent with only improved prompting\n", "game = WikiGamePrompting(\"Drupe\", \"17th parallel north\")\n", "agent = WikiAgent(task=game, tools=wiki_game_tools)\n", "agent_loop(agent, game, 40)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# WikiGame and WikiAgent with ReAct\n", "game = WikiGamePrompting(\"Drupe\", \"17th parallel north\", tools=wiki_game_tools)\n", "agent = WikiAgentReAct(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n", "agent_loop_ReAct(game, agent,40)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement a reflexion tool\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\ud83d\udd35\u26aa\u26aa\n", "> \n", "> You should spend up to 25-35 mins on this exercise.\n", "> ```\n", "\n", "The [reflexion paper](https://arxiv.org/abs/2303.11366) builds on ReAct and proposes a method that improves performance by getting LLMs to do self-reflection. The original paper looks at LLM agents in a RL set-up, where getting a reward signal on the agent's signal is slow and expensive. The key idea is to get **quick cheap feedback** from an evaluator on every proposed action, then to **reflect** on this feedback before taking the next action, as opposed to waiting for the final outcome. In their case, the evaluator was a heuristic function that estimated the reward function. \n", "\n", "We will borrow this idea and build a tool that gives feedback on our ReAct model's proposed action by performing a look-ahead. We allow the agent to suggest candidate paths, then the tool will check if these paths work and inform the model where these paths go wrong (if they do). You'll need to add this tool to the list of tools.\n", "\n", "We don't want to provide the agent the links or content of every page when it does this lookahead, as then we'd just be reimplementing a smaller version of the game *inside the game*. Instead, we'll let the agent suggest paths without seeing any content or links, and then let it know if this path works. It's very likely that a suggested link will \u2014 at some point \u2014 not be accessible from one of the pages, but this tool will still be useful to help the agent plan."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TestPathTool():\n", "    \"\"\"\n", "    Implements a tool that allows the agent to test paths from the current state of the game.\n", "\n", "    Attributes:\n", "        name (str): The name of the tool\n", "\n", "    Methods:\n", "        execute(task: WikiGame, path: str) -> str: Test if a given path is valid.\n", "\n", "        description -> dict: Provides the description of the test_path tool for the API\n", "    \"\"\"\n", "\n", "    name = \"test_path\"\n", "\n", "    def execute(self, task: WikiGame, path: str) -> str:\n", "        \"\"\"\n", "        Test if a given path is valid.\n", "\n", "        Args:\n", "            path (str): A string representing a path, e.g., \"Barack Obama -> Indonesia -> India\"\n", "            task (WikiGame): The current task being run.\n", "\n", "        Returns:\n", "            str: A message indicating whether the path is valid or where it fails.\n", "        \"\"\"\n", "        path_nodes = [node.strip() for node in path.split(\"->\")]\n", "\n", "        if not path_nodes:\n", "            return \"ERROR: Empty path provided.\"\n", "\n", "        if path_nodes[0] != task.current_page.title:\n", "            return f\"ERROR: The path should start with the current page: {task.current_page.title}\"\n", "\n", "        for i in range(len(path_nodes) - 1):\n", "            current_node = path_nodes[i]\n", "            next_node = path_nodes[i + 1]\n", "\n", "            permitted_links = (link.lower() for link in task.get_permitted_links(current_node))\n", "\n", "            if next_node.lower() not in permitted_links:\n", "                return f\"This path works until {next_node}, which is not accessible from {current_node}\"\n", "\n", "        return \"This path is valid.\"\n", "\n", "    @property\n", "    def description(self):\n", "        return {\n", "            \"type\" : \"function\",\n", "            \"function\" : {\n", "                \"name\" : \"test_path\",\n", "                \"description\" : \"Accepts a test path string in the form \\\"current_page -> page1 -> page2 -> ... -> pageN\\\" and if the path does not work, then it returns where the path goes wrong, if the path does work it returns \\\"success.\\\" Be careful that path titles can be sensitive to plurals or rephrasings. This tool is especially useful to check longer plans.\",\n", "                \"parameters\" : {\n", "                    \"type\" : \"object\",\n", "                    \"properties\": {\n", "                        \"path\" : {\n", "                            \"type\" : \"string\",\n", "                            \"description\" : \"The path you want to test, formatted as \\\" current_page -> page1 -> page2 -> ... -> pageN\\\".\"\n", "                        },\n", "                    },\n", "                    \"required\" : [\"path\"]\n", "                }\n", "            }\n", "        }\n", "\n", "TestPathTool_inst = TestPathTool()\n", "wiki_game_tools = [GetContentTool_inst, MovePageTool_inst, TestPathTool_inst]"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Now come up with your own paths to run your agent with the TestPathTool tool, to see if it has improved the agent's performance."]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["<details><summary>Help! My agent isn't using the <code>TestPathTool</code></summary>\n", "\n", "If your agent isn't using the test path tool, you may want to go back and modify your prompting. One way you could do this is to schedule a prompt to tell the agent to use the `TestPathTool` tool if it hasn't used it in its last few tool calls. Alternatively, you could just include in every `on_page_instruction` a strong indication that the agent should use this tool.\n", "\n", "</details>"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Let the LLM see its entire chat history\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> \n", "> You should spend up to 10-15 mins on this exercise.\n", "> ```\n", "\n", "You may have noticed that the agent performs significantly worse as a result of the fact that we decided to reset the chat history every time the agent encounters a new page. It often comes up with plans and doesn't follow through on them. We can fix this issue by letting the agent see the entirety of its chat history.\n", "\n", "What we have to overcome is the context window considerations, specifically with regards to the length of wikipedia pages. However, we can fix these issues by resetting **only** the outputs of the `get_content()` function each time the agent moves to a new page, instead of resetting the entire chat history.\n", "\n", "We'll modify the reset function in the `WikiAgentReAct` class to accomplish this."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WikiAgentChatHistory(WikiAgentReAct):\n", "    \"\"\"\n", "    Inherits from WikiAgentReAct and adds the ability to store and retrieve chat history.\n", "\n", "    Attributes:\n", "        model (str): The model used for generating responses (inherited)\n", "        tools (List[Any]): List of tools (inherited)\n", "        client (OpenAI): OpenAI client for API calls (inherited)\n", "        task (WikiGame): The current task being executed (inherited)\n", "        chat_history (List[dict]): History of interactions (inherited)\n", "        full_chat_history (List[dict]): Full history of interactions\n", "\n", "    Methods:\n", "        get_response(use_tool: bool = True) -> ChatCompletionMessage: Get response from the model (inherited)\n", "\n", "        execute_tool_calls(message: ChatCompletionMessage) -> List[str]: Execute tool calls from the model's response (inherited)\n", "\n", "        run(with_tool: bool = True) -> bool: Run one loop of the Wikipedia agent (inherited)\n", "\n", "        update_history(message : dict[str, str] | ChatCompletionMessage | List[dict[str, str] | ChatCompletionMessage]): Update self.chat_history and self.full_chat_history with a message or list of messages. (inherited)\n", "\n", "        reset_history(): Empty self.chat_history of the agent. (modified below)\n", "\n", "        handle_tool_calls(response: ChatCompletionMessage): Handles tool_calls in the wikipedia game context. (inherited)\n", "\n", "        handle_refusal(response: ChatCompletionMessage): Handles refusals in the wikipedia game context. (inherited)\n", "\n", "        start(): A function to put the starting instructions in agent.chat_history when the agent starts a new page or starts the game. (inherited)\n", "\n", "        run(): This function runs the agent in the wikipedia game context. (inherited)\n", "\n", "        store_chat_history(): Store the current chat history in the full chat history.\n", "\n", "        retrieve_chat_history(): Retrieve the full chat history.\n", "    \"\"\"\n", "    def reset_history(self):\n", "        \"\"\"\n", "        Replace the output of get_content tool with an indication that wikipedia content was output when the agent moves to a new page\n", "        \"\"\"\n", "        for message in self.chat_history:\n", "            if isinstance(message, dict):\n", "                if message[\"role\"] == \"tool\" and message[\"name\"] == \"get_content\" and message[\"content\"] != \"Wikipedia content was output here.\":\n", "                    message[\"content\"] = \"Wikipedia content was output here.\"\n", "                else:\n", "                    pass\n", "            else:\n", "                pass"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Now see how your agent performs:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["game = WikiGamePrompting(\"Drupe\", \"17th parallel north\", tools=wiki_game_tools)\n", "agent = WikiAgentChatHistory(game, model=\"gpt-4o-mini\", tools = wiki_game_tools)\n", "agent_loop_ReAct(game, agent, 40)"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 5\ufe0f\u20e3 Bonus\n", "\n", "> ##### Learning Objectives\n", ">\n", "> - Implement additional tools for elicitation\n", "> - Explore some of your own ideas for elicitation\n", "> - Explore some of the current research in elicitation"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Additional Tool use"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement a page summary tool\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> \n", "> You should spend up to 10-15 mins on this exercise.\n", "> ```\n", "\n", "Implement a tool that allows an agent to get a summary of any page that is accessible from its current page. This imitates a feature on wikipedia where you can see a short summary of a page when you hover over the link to it. You could either implement this tool so that the agent can just read the summary, or you can modify the `move_page` tool, so that the agent sees a summary of the page it wants to move to, and can then make a decision whether to ultimately move page."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GetAccessiblePageSummaryTool():\n", "    \"\"\"\n", "    Implements a tool that allows the agent to get the summary of a Wikipedia page (you should use the get_page_summary function from the agent class)\n", "    \"\"\"\n", "\n", "    name = \"get_accessible_page_summary\"\n", "\n", "    @staticmethod\n", "    def get_page_summary(task: WikiGame, page_title: str) -> str:\n", "        \"\"\"\n", "        Get summary of a wikipedia page, to the last full stop within the first 500 characters. This is used to give a brief overview of the page to the agent.\n", "\n", "        Args:\n", "            page (str): The Wikipedia page title.\n", "            task (WikiGame): The current task object.\n", "\n", "        Returns:\n", "            str: The summary of the Wikipedia page.\n", "        \"\"\"\n", "        page = task.get_page(page_title)\n", "        if page in task.get_permitted_links():\n", "            summary = page.content[:500]\n", "            last_period_index = summary.rfind(\".\")\n", "            return (\n", "                summary[: last_period_index + 1] if last_period_index != -1 else summary\n", "            )\n", "        else:\n", "            return \"This page is not accessible from the current page.\"\n", "\n", "    @property\n", "    def description(self):\n", "        \"\"\"\n", "        Provides the description of the get_page_summary tool\n", "\n", "        Returns:\n", "            dict: The description of the tool for the API\n", "        \"\"\"\n", "        return {\n", "            \"type\": \"function\",\n", "            \"function\": {\n", "                \"name\": self.name,\n", "                \"description\": \"Get the summary of a wikipedia page you are considering moving to, to the last full stop within the first 500 characters. The page needs to be accessible via a link from the current page. Anything which corresponds to a link you can select will be wrapped in <link></link> tags.\",\n", "                \"parameters\": {\n", "                    \"type\": \"object\",\n", "                    \"properties\": {\n", "                        \"page_title\": {\n", "                            \"type\": \"string\",\n", "                            \"description\": \"The wikipedia page you want to get the summary of.\",\n", "                        }\n", "                    },\n", "                    \"required\": [\"page_title\"],\n", "                },\n", "            },\n", "        }\n", "\n", "GetAccessiblePageSummaryTool_inst = GetAccessiblePageSummaryTool()\n", "wiki_game_tools = [GetContentTool_inst, MovePageTool_inst, TestPathTool_inst, GetAccessiblePageSummaryTool_inst]"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement an arbitrary page summary/content tool\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\u26aa\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> \n", "> You should spend up to 5-10 mins on this exercise.\n", "> ```\n", "\n", "Now implement a tool that allows the agent to suggest dany wikipedia page, and get a brief summary of it. This may be helpful for the agent to formulate plans into the future."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GetAnyPageContent():\n", "    \"\"\"\n", "    Implements a tool that allows the agent to get the content of any Wikipedia page (not wrapped in link tags).\n", "    \"\"\"\n", "\n", "    name = \"get_any_page_content\"\n", "\n", "    @staticmethod\n", "    def execute(task: WikiGame, page_title: str | None = None) -> str:\n", "        \"\"\"\n", "        Get the content of any wikipedia page\n", "\n", "        Also provides current page content if no page_title is provided.\n", "\n", "        Args:\n", "            page_title (str): The title of the Wikipedia page\n", "            task (WikiGame): The current task being run.\n", "\n", "        Returns:\n", "            str: The content of the page (not wrapped in link tags).\n", "        \"\"\"\n", "        if page_title:\n", "            page = task.get_page(page_title)\n", "            content = page.content\n", "            return content\n", "        else:\n", "            content = task.current_page.content\n", "            permitted_links = get_permitted_links(task.current_page)\n", "            for word in sorted(permitted_links, key=len, reverse=True):\n", "                content = re.sub(\n", "                    r\"\"\"(\\s|[,.)!?;:'\"])(\"\"\" + re.escape(word) + r\"\"\")(\\s|[,.)!?;:'\"s])\"\"\",\n", "                    r\"\"\"\\1<link>\\2</link>\\3\"\"\",\n", "                    content,\n", "                    count=1,\n", "                    flags=re.IGNORECASE,\n", "                )\n", "            return content\n", "\n", "    @property\n", "    def description(self):\n", "        \"\"\"\n", "        Provides the description of the get_any_page_content tool\n", "\n", "        Returns:\n", "            dict: The description of the tool for the API\n", "        \"\"\"\n", "        return {\n", "            \"type\": \"function\",\n", "            \"function\": {\n", "                \"name\": self.name,\n", "                \"description\": \"Get all the content for any wikipedia page.\",\n", "                \"parameters\": {\n", "                    \"type\": \"object\",\n", "                    \"properties\": {\n", "                        \"page_title\": {\n", "                            \"type\": \"string\",\n", "                            \"description\": \"The wikipedia page you want to get the content of.\",\n", "                        }\n", "                    },\n", "                    \"required\": [\"page_title\"],\n", "                },\n", "            },\n", "        }\n", "\n", "GetAnyPageContentTool_inst = GetAnyPageContent()\n", "wiki_game_tools = [GetContentTool_inst, MovePageTool_inst, TestPathTool_inst, GetAnyPageContentTool_inst]"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Implement additional rules\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\u26aa\u26aa\u26aa\n", "> Importance: \ud83d\udd35\u26aa\u26aa\u26aa\u26aa\n", "> ```\n", "\n", "Allow the game to have additional rules. Some suggestions are a \"No country\" rule, and a \"No articles above a given length\" rule, but feel free to add more if you think of any others. With all of our elicitation methods, the agent generally only fails if the path is impossible or unreasonably hard. To implement a no country rule, you may want to use the wikipedia API's \"categories\" attribute for `WikipediaPage` objects.\n", "\n", "First, let's modify the prompts in the Wikigame class so that we inform the agent about the additional rules it will have to abide by."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WikiGameRules(WikiGamePrompting):\n", "    \"\"\"\n", "    Inherits from WikiGamePrompting and adds the ability to store and display the rules of the game.\n", "\n", "    Attributes:\n", "        starting_page (str): The title of the starting page (inherited)\n", "        goal_page (str): The title of the goal page (inherited)\n", "        current_page (WikipediaPage): The current Wikipedia page (inherited)\n", "        page_history (List[str]): The history of pages visited (inherited)\n", "        full_chat_history (List[dict]): The full history of messages sent (inherited)\n", "\n", "    Methods:\n", "        get_page(title: str) -> WikipediaPage: Get a Wikipedia page object given a title (inherited)\n", "\n", "        get_page_summary(page: WikipediaPage | None = None) -> str: Get the summary of a Wikipedia page (inherited)\n", "\n", "        get_permitted_links(title: Optional[str] = None) -> list[str]: Get permitted links for the current page (inherited)\n", "\n", "        is_permitted_link(link: str) -> bool: Check if a link is permitted (inherited)\n", "\n", "        system_instruction -> dict: Generate the starting instructions for the game (inherited)\n", "\n", "        on_page_instruction -> dict: Generate instructions for the current page (inherited)\n", "\n", "        next_step_instruction -> dict: Generate instructions for the next step (inherited)\n", "\n", "        check_win() -> bool: Check if the game has been won (inherited)\n", "    \"\"\"\n", "\n", "    def __init__(self, starting_page: str, goal_page: str, rules: List[Literal[\"no countries\", \"no pages above length 30000\"]], tools : list = None):\n", "        super().__init__(starting_page, goal_page, tools)\n", "        self.rules = rules if rules else None\n", "\n", "    @property\n", "    def system_instruction(self):\n", "        \"\"\"\n", "        Provide improved starting instructions for the game.\n", "\n", "        Returns:\n", "            dict: The starting instructions. \"role\" is \"system\" for system messages.\n", "        \"\"\"\n", "        tool_descriptions = \"\\n\".join([tool.description[\"function\"][\"name\"] + \":\" + tool.description[\"function\"][\"description\"] for tool in self.tools])\n", "        if self.rules:\n", "            return {\n", "            \"role\" : \"system\",\n", "            \"content\" : f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tools))} tools, which are:\\n{tool_descriptions}\\n\\nThe additional rules of the game are: {\",\".join(self.rules)}\"\"\"\n", "        }\n", "        else:\n", "            return {\n", "            \"role\" : \"system\",\n", "            \"content\" : f\"\"\"You are a wikipedia-racing AI. Your goal is to reach {self.goal_page.title} by accessing links from wikipedia pages. Your current page is {self.current_page.title}. You have access to {str(len(self.tools))} tools, which are:\\n{tool_descriptions}\"\"\"\n", "        }\n", "\n", "    @property\n", "    def on_page_instruction(self):\n", "        \"\"\"\n", "        Provide improved instructions for the current page.\n", "\n", "        Returns:\n", "            dict: The instructions for the current page. \"role\" is \"user\" for user messages.\n", "        \"\"\"\n", "        return {\n", "            \"role\" : \"user\",\n", "            \"content\" : f\"\"\"You are currently on page: {self.current_page.title}. Make sure you start by reasoning about what steps you should take to get to the article on {self.goal_page.title}. When coming up with a strategy, make sure to pay attention to the path you have already taken, and if your current strategy doesn't seem to be working out, try something else. In case you're unsure, {self.goal_page.title} has the following summary:\\n[Begin Summary]\\n{self.get_page_summary(self.goal_page)}\\n[End Summary]\\n\\nThe pages you've visited so far are: {\" -> \".join(self.page_history)}\\n\\nThe rules of the game are: {\",\".join(self.rules)}\"\"\"\n", "        }"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Now let's implement these rules by modifying the `MovePageTool` class, so that the agent can only move page if it's within the rules of the game."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MovePageTool_rules(MovePageTool):\n", "    \"\"\"\n", "    Inherits from move_page_tool and adds the ability to check the rules of the game.\n", "    \"\"\"\n", "\n", "    @staticmethod\n", "    def execute(new_page: str, task: WikiGame) -> str:\n", "        \"\"\"\n", "        Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page.\n", "\n", "        Only allow the agent to move if it is permitted by the rules.\n", "\n", "        Args:\n", "            task (BaseWikiGame): The current task object.\n", "            new_page (str): The title of the new page to move to.\n", "\n", "        Returns:\n", "            str: A message indicating the result of the move\n", "        \"\"\"\n", "        new_page_normalized = new_page.replace(\"_\", \" \")\n", "        if task.is_permitted_link(new_page_normalized):\n", "            if \"no countries\" in task.rules and any(\"countries in\" in category for category in task.get_page(new_page_normalized).categories.lower()):\n", "                return f\"Couldn't move page to {new_page}. This page is in the category of countries.\"\n", "            if \"no pages above length 30000\" in task.rules and len(task.get_page(new_page_normalized).content) > 30000:\n", "                return f\"Couldn't move page to {new_page}. This page is above the maximum length of 30000 characters.\"\n", "            task.current_page = task.get_page(new_page_normalized)\n", "            task.page_history.append(task.current_page.title)\n", "            return f\"Moving page to {task.current_page.title}\"\n", "        else:\n", "            return f\"Couldn't move page to {new_page}. This is not a valid link.\"\n", "\n", "    @property\n", "    def description(self):\n", "        \"\"\"\n", "        Provides the description of the modified move_page tool\n", "\n", "        Returns:\n", "            dict: The description of the move_page tool for the API\n", "        \"\"\"\n", "        return {\n", "            \"type\": \"function\",\n", "            \"function\": {\n", "                \"name\": self.name,\n", "                \"description\": \"Changes your current page to a specified new page which is accessible via a link from the current page. You can only call this function once at a time, as it will take you to a different page. If any pages violate the rules of the game\",\n", "                \"parameters\": {\n", "                    \"type\": \"object\",\n", "                    \"properties\": {\n", "                        \"new_page\": {\n", "                            \"type\": \"string\",\n", "                            \"description\": 'The title of the new page you want to move to. This should be formatted the way the title appears on wikipedia (e.g. to move to the wikipedia page for the United States of America, you should enter \"United States\"). Underscores are not necessary.',\n", "                        }\n", "                    },\n", "                    \"required\": [\"new_page\"],\n", "                },\n", "            },\n", "        }"]}, {"cell_type": "markdown", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### Exercise - Try further elicitation methods\n", "> ```yaml\n", "> Difficulty: \ud83d\udd34\ud83d\udd34\ud83d\udd34\u26aa\u26aa\n", "> Importance: \ud83d\udd35\ud83d\udd35\u26aa\u26aa\u26aa\n", "> ```\n", "Read some of the resources we linked on the Intro to LLM agents page, and explore some of your own methods to elicit improved performance on the task. If you start seeing diminishing returns from elicitation (due to saturating performance on the task), come up with ways to make the task harder; or better yet, construct your own, more difficult, task."]}], "metadata": {"language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 2}